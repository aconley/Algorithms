\topglue 0.5in
\centerline{Notes on Knuth Chapter 7.1}
\vskip 0.5in

\noindent
{\bf Section 7.1.1 Basic Identities} \hfil\break
\vskip 0.05in
\noindent [p 50] Eq (9) states $\left( x \oplus y \right)
\oplus x = y$.  Why?  \hfil\break
Well, $\oplus$ is not distributive, even with itself,
but it is commutative and associative. The above is therefore
equivalent to $y \oplus \left( x \oplus x \right) = y \oplus 0 = y$.
The same argument shows that $\left( x \oplus y \right) \oplus y = x$.

\vskip 0.05in
\noindent [p 51] Why are Eq (13)-(15) true? \hfil\break
I don't see how to derive (13), or (14) besides just writing out the truth table, but (15) is:
$x \oplus y = \left(x \vee y\right) \wedge \overline x \wedge y$, which
is true by inspection (either x or y has to be true, but not both).
These can be expanded using (12) and (1) to give
$x \oplus y = \left(x \vee y\right) \wedge \left(\overline{x} \vee \overline{y}
\right) = \left(x \wedge \left(\overline{x} \vee \overline{y}\right)\right)
\vee \left(y \wedge \left(\overline{x} \vee \overline{y}\right)\right)$.
Applying (1) to each of these terms again gives things like
$\left(\overline{x} \wedge x\right) \vee \left(\overline{y} \vee x\right) =
\overline{y} \vee x$, which, when applied to both terms gives
$x \oplus y = \left(x \wedge \overline{y}\right) \vee \left(\overline{x}
\wedge y\right)$, which is the claimed identity.

\vskip 0.1in
\noindent
{\bf Section 7.1.1 Functions of n variables} \hfil\break

\noindent [p51] Why does the functional decomposition
of eq (16) and (17) work? \hfil\break
First, note that $h$ is 0 if
$f\left(x_1,\ldots,x_{n-1},0\right) = f\left( x_1,\ldots,x_{n-1},1\right)$, so
in this case we have (on the right hand side of (16)),
 $g\left(x_1,\ldots,x_{n-1}\right) \oplus 0 = f\left(x_1,\ldots,x_{n-1},0\right)$.
 Since we already said that $f\left(x_1,\ldots,x_{n-1},0\right) = f\left( x_1,\ldots,x_{n-1},1\right)$, this must be true.  
 
If $f\left(x_1,\ldots,x_{n-1},0\right) \neq f\left( x_1,\ldots,x_{n-1},1\right)$,
then $h\left(x_1,\ldots,x_{n-1}\right)=1$, so we have $1\, \wedge\, x_n
= x_n$.  Thus, the rhs of (16) becomes $f\left(x_1,\ldots,x_{n-1},0\right) 
\, \oplus \, x_n$.  Now note that if $x_n = 1$ this is
$f\left(x_1,\ldots,x_{n-1},0\right) \, \oplus 1 = 
\overline{f\left(x_1,\ldots,x_{n-1},0\right)}$.  But we already said that
$f\left(x_1,\ldots,x_{n-1},0\right) \neq f\left( x_1,\ldots,x_{n-1},1\right)$,
so this is just $f\left(x_1,\ldots,x_{n-1},1\right)$, which is what we want.
Similarly, for $x_n = 0$, we just get
$f\left(x_1,\ldots,x_{n-1},0\right) \oplus 0 = f\left(x_1,\ldots,x_{n-1},0\right)$.

\vskip 0.05in
\noindent [p52] That demonstrates why (16) works -- why does (18), 
the ``law of development'', work?\hfil\break
First, let's say that $x_n = 0$.  Then only the first term applies, giving
$f\left(x_1,\ldots,x_{n-1},0\right) \wedge 1 = f\left(x_1,\ldots,x_{n-1},0\right)$,
which is indeed the value of $f\left( x_1,\ldots,x_n \right)$ when $x_n = 0$.
It works the same way for $x_n = 1$.

\vskip 0.05in \noindent [p55] {\bf Theorem Q}\hfil\break 
A prime implicant corresponds to a 1 in the
truth table of the function.  Since the function is monotone, the implicant
can't become false (0) when any of it's values go from 0 to 1.  If one
of the terms in the prime implicant were, say, $\overline{x_i}$, then
when that changed from 0 to 1, the implicant would become false.  This
is not allowed.

\vskip0.1in
\noindent
{\bf Section 7.1.1 Satisfiability}\hfil\break

\noindent [p56] 3SAT\hfil\break
The text uses problem 39 to explore a fairly general form where the 
operators between variables
in the function can be any of the 16 boolean 2-ary functions, but it's
interesting enough to explore the more restrictive reduction from SAT --
which is how to turn a general problem in conjunctive normal form
into one with only three literals per clause.  After all, we know that
any boolean function can be written that way, so while it may be
possible to make a more efficient 3SAT instance using problem 39,
just studying how to do this with CNF form is enough to imply that
all boolean functions can be turned into 3SAT.

Clearly it's enough to figure out how to turn any clause $t_1 \vee \ldots
\vee t_n$ into a conjunction of 3-literal clauses.  To do this, one introduces
``nuisance'' variables $x_i$ for $2 \leq i \leq n - 2$ and uses them to sandwich
each literal.
$$
t_1 \vee \ldots \vee t_n = \left(t_1 \vee t_2 \vee x_2\right)
\land \left(\bar x_2 \vee t_3 \vee x_3\right)
\land \left(\bar x_3 \vee t_4 \vee x_4\right)
\land \ldots \land \left(\bar x_{n-2} \vee t_{n-1} \vee t_n\right) .
$$
Actually, they aren't {\it identical}, they are {\it equisatisfiable}.

So, why does this work?  Well, imagine this clause is satisfiable.
Then at least one of the $t_i$ must be 1. 
The point is that we can force all of the other 3-literal clauses
to be true by a judicious choice of the $x_i$.   Say that the
literal is $t_j$.  We then set $x_k$ for $k \le j$ to 1,
and $x_k$ for $k \geq j$ to 0 and the clause is satisfiable.

Conversely, say that the clause is not satisfiable, so all the $t$
are zero.  Then to satisfy the new form we need $x_2 = 1$ for
the first clause, but then that forces $x_3 = 1$ in the second,
etc., until we get to the last clause where we need $x_{n-2} = 0$
but it has been forced to be 1 by the previous clause.  So therefore
if the original clause is satisfiable we can satisfy the new one, and
if it isn't then we can't.

\vskip0.1in
\noindent
{\bf Section 7.1.1 Simple Special Cases}\hfil\break

\noindent [p57] {\bf Theorem H} \hfil\break
The first step in the formula is to use the 
distributive law (2): $\left(x \wedge y\right) \vee z = \left(x \vee z\right) 
\wedge \left(y \vee z\right)$.
The second step makes use of the fact that $\vee$ is commutative to move all the $y$s 
rightward in the left term.  We then have $\left(x_1 \vee \overline{x}_2
\vee \ldots \vee \overline{x}_k\right) \vee \overline{y}_1 \vee \ldots \vee 
\overline{y}_k
\geq \left(x_1 \vee \overline{x}_2 \vee \ldots \vee \overline{x}_k\right)$,
which is clearly true since the extra terms can either leave the truth value 
unchanged or increase it from 0 to 1.  The same logic applies to the second term.

\vskip0.05in \noindent [p58] In the example of Horn clauses following theorem H, where 
do the propositions come from? \hfil\break  
Well, take the first one: $\bf xE \Rightarrow xT$ states
that it is allowable for an expression to start with {\bf x} if and only if
it is allowable for a term to start with {\bf x}; this is clear from the first
line of the specification.  

How do these convert into Horn clauses?  Well, recall that $x \Rightarrow y$
is the same as $\overline{x} \wedge y$ (Table 1).  The Horn clause expression is
just all of those $\wedge$ed together.

\vskip0.1in
\noindent {\bf Section 7.1.1 Medians}\hfil\break

\noindent [p63] Self duality: in the discussion after (46), why does a formula
need to be indifferent to swapping $\wedge$ and $\vee$?  Recall De Morgan's
laws (11 and 12): $\bar{x \wedge y} = \bar x \vee \bar y$ and $\bar{x \vee y} =
\bar x \wedge \bar y$.  So, using (46), when we negate the entire function,
we get something like $\bar{\left(x_i \wedge \ldots \wedge x_j\right) \vee
\left(x_k \wedge \ldots \wedge x_l\right) \vee \ldots} =
\left(\bar x_i \vee \ldots \vee \bar x_j\right) \wedge
\left(\bar x_k \vee \ldots \vee \bar x_l\right) \wedge \ldots$;
if this is to be equal to the original with the variables negated, then
indeed we must be able to interchange $\vee$ and $\wedge$.

\vskip0.1in
\noindent
{\bf Section 7.1.1 Threshold functions}\hfil\break

\noindent [p75] Negative weights: to get rid of negative weights,
the replacements $x_j \gets \bar x_j$ and $w_j \gets -w_j$ seem
pretty obvious, but what about the $t \gets t + \left|w_j\right|$?
Well, consider some variable $x_j$.  the old contribution was
$w_j x_j$, the new one is $-w_j \bar x_j$.  The first evaluates to
$0, w_j$ for $x_j = 0, 1$, the second to $-w_j, 0$.  These aren't
equal, so the right hand side ($t$) also needs to be adjusted.
Let's say the old threshold was 2, and $w_j = -2$.  Then with
the negative weight the rest of the terms need to add up to 2 or 4
for $x_j = 0, 1$.  For the new form, if we didn't adjust $t$, they
would have to add up to $0, 2$, so the formula are no longer
equivalent.  If we add $\left|-w_j\right| = 2$ so that $t \gets 4$,
then they need to be $2, 4$, as before.

\vskip 0.05in \noindent [p 77] {\bf Theorem T} \hfil\break
The proof works because the number
of vectors where we must have $f\left(x^{\left(m\right)}\right) = 
g\left(x^{\left(m\right)}\right) = 1$ is $N\left(f\right) - k = N\left(g\right) - k$.
That means there must also be $k$ vectors where $f\left(y^{\left(k\right)}\right) = 1$
and $g\left(y^{\left(k\right)}\right) = 0$.

In the next step, note that $w \cdot x^{\left(j\right)} \geq t$ for each of the $k$
such values.

\vfil\break
\topglue 0.5in
\centerline{Notes on Knuth Chapter 7.2}
\vskip 0.5in

\noindent
{\bf Section 7.2.1.2 Algorithm L} The important thing to note here is that
this generates only {\it distinct} permutations -- so 1223 has only 12
permutations, not 24, because in any permutation the two 2s can be
exchanged.

It's useful to create an example of this
in action.  Consider the sequence $246$ -- so $a_1 = 2$, $a_2 = 4$,
$a_3 = 6$, and the convenience value $a_0$ is, say $a_0 = 0$.
So, step by step:\hfil\break
{\bf L1} Output 246.\hfil\break
{\bf L2} Let $j \leftarrow 2$, which does satisfy $a_2 < a_3$.\hfil\break
{\bf L3} Set $l \leftarrow 3$.  We have $a_j < a_l$.  Interchange
  $a_2$ and $a_3$, which gives us $264$.\hfil\break
{\bf L4} is a null step, since $j + 1 = 3$ is the last element.\hfil\break
{\bf L1} Output 264.\hfil\break
{\bf L2} Let $j \leftarrow 2$, but now $a_2 > a_3$, so decrease
  $j$ until $j = 1$ (since $a_1 < a_2$).\hfil\break
{\bf L3} Set $l \leftarrow 3$.  $a_1 < a_2$, so swap to form
 $462$.\hfil\break
{\bf L4} Reverse $a_2$ and $a_3$ to get 426.\hfil\break
{\bf L1} Output 426.\hfil\break
{\bf L2} $j \leftarrow 2$, since $a_2 < a_3$ ($2 < 6$).\hfil\break
{\bf L3} $n \leftarrow 3$, swap to get 462.\hfil\break
{\bf L4} Swapping is null.\hfil\break
{\bf L1} Output 462.\hfil\break
{\bf L2} $j \leftarrow 1$.\hfil\break
{\bf L3} $n \leftarrow 2$, swap to get $642$.\hfil\break
{\bf L4} reverse from 2 to get $624$.\hfil\break
{\bf L1} output 624.\hfil\break
{\bf L2} $j \leftarrow 2$.\hfil\break
{\bf L3} $l \leftarrow 3$.  Swap to get $642$.\hfil\break
{\bf L4} Reversing is null.\hfil\break
{\bf L1} Output 642.\hfil\break
{\bf L2} $j$ is 0, so terminate.\hfil\break
The output is ${246, 264, 426, 462, 624, 642}$, which is in lexicographic
order.

\end