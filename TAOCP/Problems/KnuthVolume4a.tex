\topglue 0.5in
\centerline{\tt Knuth 7}
\vskip 0.5in

\noindent
{\bf Problem 2} We can start with any solution to the normal problem (where we count
from 1 to $n$ instead of 0 to $n-1$ and simply
append 00 on the front.  Therefore, we must have $n-1 = 4m - 1$ or $n-1 = 4m$ --
that is, $n \bmod 4$ is 0 or 1.

\vskip 0.1in
\noindent
{\bf Problem 5} There are $2 n \choose 2$ pairs of positions (since we don't care about 
the ordering of each pair.  Of those, $2 n - k - 1$ satisfy the condition (the first member of the 
pair can be in position 1 up to $2 n - k - 1$ before the second one runs off the end).
A guess as to the number would be to falsely assume the probabilities are independent --
which is clearly nonsense.  The total number of arrangements is $2 n \choose 2, \ldots, 2$,
so the product  ${2 n \choose 2, \ldots, 2} \prod_{j=1}^n \left(2 n - k - 1\right) / {2 n \choose n}$
is an estimate.

\vskip 0.1in
\noindent
{\bf Problem 7} The number of uncompleted pairs $u_i$ must start at 0 at the left of
the sequence (before processing the first number) and end at 0 when we finish.
After each number it can either increase by one or decrease by one.  The longest
sequence we can imagine where we never exceed, 6 is
$\{0, 1, \ldots, 5, 6, 5, 6, \ldots, 2, 1, 0\}$.

How can we make use of this information?  Well, one thing we know about Langford
pairs is that each term $k$ contributes a count of 1 to $u$ for $k$ spaces -- that
is, after we process, say, 4, we know that $u$ will be increased by 1 for 4 more spaces
until we close out the pair -- that is, it increases the sum over $u$ by $k+1$.
Thus, $\sum_{i=1}^{2 n} u_i = \sum_{i=1}^{k} k + 1 = {n+1 \choose 2} + n$.  The
other sum, from the above sequence, is, for $u_i$ never exceeding 6,
$11 n - 30$.  So we need $11  n - 30 \ge {n + 1 \choose 2} + n$, or $n \le 15$,
and it doesn't work.

\vskip 0.1in
\noindent
{\bf Problem 39} $G \setminus e$ is always spanning (includes all the vertices of $G$),
but not induced (contains all the edges).

\vskip 0.1in
\noindent
{\bf Problem 40} (a) A spanning subgraph has all $n$ vertices.  So the only
question is which subset of the $e$ edges are present.  There are $2^e$ 
possibilities. (b) Now the question is only which subset of the vertices
are included; there are $2^n$ possibilities (assuming we allow the empty
subgraph).

\vskip 0.1in
\noindent
{\bf Problem 41} (a) 1 and 2. (b) 0 and 3.

\vskip 0.1in
\noindent
{\bf Problem 55} Two different ways to write this: $n_1 \times n_2 +
n_1 \times n_3 + \ldots + n_1 \times n_k + n_2 \times n_3 + \ldots + 
n_{k-1} \times n_k$.  Or, alternatively, start with the complete graph
and subtract all the edges between vertices in the same components:
${N \choose 2} - {n_1 \choose 2} - {n_2 \choose 2} - \ldots - {n_k \choose 2}$
(where $N = \sum_i n_i$).

\vskip 0.1in
\noindent
{\bf Problem 56} True.  Simple means that there are not multiple arcs between
the same vertices in the digraph.  That rules out self edges, since converting
a multigraph to a digraph would add two arcs for each self loop in the multigraph.
Therefore, the multigraph can't have any self loops, and is a graph.

\vskip 0.1in
\noindent
{\bf Problem 57} This would be true if the question asked about strongly
connected components, but it doesn't.  So false.  A trivial example is to
have two of three vertices point into the third vertex.

\topglue 0.5in
\centerline{\tt Knuth 7.1.1}
\vskip 0.5in

\noindent
{\bf Problem 3} (a) max corresponds to logical or: $\vee$ (b) min corresponds to 
logical and: $\wedge$ (c) $-x$ is negation or right complementation: $\overline{x}$
(d) $x \cdot y$ is equivalence: $x \equiv y$.

\vskip 0.1in
\noindent
{\bf Problem 4} (a) This is straightforward but extremely tedious -- that is,
it would be a good thing to write a program to do.  In any case, the idea
is to start with the truth tables of the left and right projection operators
$x$ and $y$ (0011 and 0101, respectively), and NAND $\bar \land$ (1110)
and try successively combining them.  For example, $\bar L = L \bar \land L = x \bar
\land x$, $\bar R = R \bar \land R = y \bar \land y$.  Then try combinations:
$L \bar \land \bar L = 0011 \bar \land 1100 = 1111 = T = x \bar \land x \bar \land x$.
Continuing, $\vee = \bar L \bar \land \bar R = 1100 \bar \land 1010 = 0111 =
\left(x \bar \land x\right) \bar \land \left(y \bar \land y\right)$,
$\land = \bar \land \bar \land \bar \land = 1110 \bar \land 1110 = 0001 = 
\left(x \bar \land y \right) \bar \land \left( x \bar \land y \right)$,
$\supset = x \bar \land \bar \land = 0011 \bar \land 1110 = 1101 = 
x \bar \land \left(x \bar \land y\right)$, $\subset = \bar \land \bar \land =
y \bar \land \left(x \bar \land y\right)$.
The toughest ones are $\oplus = \supset \bar \land \subset = 1011 \bar \land 1101 =
0110 = y \bar \land \left(x \bar \land x\right) \bar \land \left(x \bar \land
\left(x \bar \land y \right)\right)$, $\perp$, and $\bar \subset, \bar \supset$.
The latter two are just $\subset \bar \land T$ and $\supset \bar \land T$,
and $\perp = T \bar \land T$.

\vskip 0.1in \noindent {\bf Problem 12} ({\it multilinear representation}).\hfil\break
a) Recall that (22) has the truth table $1100\,1001\,0000\,1111$, and
the expansion using Boole's law is given by (23).  This can rather easily
be turned into a polynomial by leaving any term $t$ as $t$, and
$\bar t \mapsto t$.  Then $\land \mapsto \times$, but what about $\vee$?
Well, $x \vee y = x + y - x y$.  Furthermore, since each variable is either
0 or 1, $t^n = t$ for any $n$.  So this turns into a giant algebraic expansion,
which can be fed to something like Mathematica to get $1 - y - x z + 2 x y z - w +
wy + wx + wxz - 2 w x y z$.\hfil\break
\vskip 0.05in
\noindent b) Use the Boolean decomposition directly.  A boolean function of $n$ 
variables can be written 
$$f\left(x_1, \ldots, x_n\right) = \left(f_1 \left(x_1, \ldots, x_{n-1}\right)
\land {\bar x_n}\right) \vee \left(f_2 \left(x_1, \ldots, x_{n-1}\right)
\land x_n\right)
$$ 
where $f_1\left(x_1, \ldots, x_{n-1}\right) =
f\left(x_1, \ldots, x_{n-1}, 0\right)$ and $f_2\left(x_1, \ldots, x_{n-1}\right) =
f\left(x_1, \ldots, x_{n-1}, 1\right)$.  Converting to the integral form,
this can be expanded to form $f = \left(f_1 \left(1 - x_n\right)\right) \vee
\left(f_2 x_n\right) = f_1 + \left(f_2 - f_1\right) x_n$.  Now,
$f_1$ and $f_2$ are both drawn from the space of functions of $n-1$ variables.
If the maximum possible (in an absolute value sense) coefficient 
for such a function is $\alpha_{n-1}$, then we can use the previous relation
to compute the limit on $\alpha_n$.  There are two cases -- we are
considering a term that does {\it not} include $x_n$, which is the first
term ($f_1$), or we are considering a term that does include $x_n$ which is
the $\left(f_2 - f_1\right) x_n$ term.  In the first case, the maximum coefficient
hasn't changed.  In the second, the maximum absolute value of $\alpha_n$
is $2 \alpha_{n-1}$ (if they occur with the opposite sign in $f_1$ and $f_2$).
Combine this with the fact that the maximum coefficient for a function of $x_1$
only is 1 ($1 - x_1$ or $x_1$), and the maximum absolute value of any coefficient 
is $2^{n-1}$.  Note the above also implies that the maximum coefficient for
a term containing $m$ of the $x_i$ is $2^{m-1}$.

\vskip 0.05in
\noindent c) Rather than multiplying out all the terms as in a), consider
that each function is comprised of a product of $x_j$ and $1 - x_k$s --
e.g., $\left(1 - x_3\right) x_4 \left(1 - x_8\right)$.  Therefore, if each $x_i$
is between 0 and 1, then each term is between 0 and 1.  When we or
them together, the result is $a \vee b = a + b - a b$, which, for
$a, b$ between 0 and 1, has a minimum at $a = b = 0$ of 0 and a maximum
when $a = b = 1$ of 1.  So therefore we must have $0 \leq f \leq 1$.

\vskip 0.05in
\noindent d) Note that the final expression if we multiply everything out
must be linear in each variable (i.e., with all other variables fixed).  We
know from the previous item that the maxima must occur at some set
of 0, 1 assignments.  Since the functions are linear, and $g \geq f$
at those endpoints, it must also be greater everywhere in between.

\vskip 0.05in
\noindent e) Since $f$ is monotone, it must be possible to write
$\partial f / \partial x_i = h\left(x\right) - g\left(x\right)$ for some
$h$ and $g$ such that $h \geq g$ for all $x$, and where we use d)
to convert this from a function defined only on 0, 1 to one defined on
real arguments.

\vskip 0.1in \noindent {\bf Problem 13} This is just the multilinear representation
from the previous problem, since the expectation value of any product
of $x_1 \cdot x_2 \cdot \ldots \cdot x_n$ is just $p_1 \cdot p_2 \cdot \ldots \cdot p_n$.

\vskip 0.1in \noindent {\bf Problem 18} Try setting $u_i = 1$ for all $i$ and
$v_j = 0$ for all $j$.  Then $f$ would be true in the DNF, but $f$ would
be false from the CNF.

\vskip 0.1in \noindent {\bf Problem 19} For the CNF we are looking for 
the points where (22) is {\it false}, not true, since each clause represents
such a string.  The strings $wxyz$ where (22) is false are
0010, 0011, 0101, 0110, 1000, 1001, 1010, 1011.  The maximal
subcubes are therefore 10**, 0*10, *01*, and 0101.  Each one is a barred
literal, each 0 an unbarred one (since we are looking for falsehood, so this
corresponds to $\left(\bar w \vee x\right) \land \left(w \vee \bar y \vee z\right)
\land \left(x \vee \bar y\right) \land \left(w \vee \bar x \vee y \vee \bar z\right)$.

\vskip 0.1in \noindent {\bf Problem 38} No, it's easy to test satisfiability
for a function in disjunctive normal form.  In some sense it's the opposite
of SAT -- if there are any implicants at all, one can just read off the values
that make it true, and the function is satisfiable.  The hard part, by symmetry,
is figuring out if the function is ever {\it false}.

\vskip 0.1in \noindent {\bf Problem 41} State the pigeonhole principle in
conjunctive normal form.  Well, the first task is to make clauses saying
that each of the $m$ pigeons is in at least one hole.  If we let the
variable $x_{jk}$ mean that pigeon $j$ is in hole $k$, then for each
$1 \leq j \leq m$ we must have $\left(x_{j1} \vee \cdots \vee x_{jn}\right)$.
Next we have to add clauses saying two pigeons can't be in the {\it same}
hole -- to wit $\left(\bar x_{ik} \vee \bar x_{jk}\right)$ for $i$ and $j$ ranging
over the distinct $m$ pigeons and $k$ the $n$ holes.  Actually, that's slightly redundant;
we can cut out about half the clauses by having $1 \leq i \le j \leq m$ and
$1 \leq k \leq n$ for these terms.

\vskip 0.1in \noindent {\bf Problem 48} The problem is really asking if we
can convert indefinite Horn clauses into definite ones -- which means can
we convert a clause with no unbarred literals (indefinite) into one or more with
exactly one (definite), since clearly we don't need to do anything to the
ones that already are definite.  So, we have a clause like $\bar x_1 \vee
\ldots \vee \bar x_n$.  As seems to be the standard approach here, make
some new variable $y$.  Now or it into each clause: $\bar x_1 \vee \ldots
\bar x_n \vee y$.  Now solve that problem using, e.g., {\bf Algorithm C},
noting that our augmented function must be satisfiable since it is definite.
Now, if $y$ shows up in the core, then the original formula was unsatisfiable.
In practice, we would stop as soon as {\bf C5} was about to set $y$ to true.

\vskip 0.1in \noindent {\bf Problem 56} The formula is satisfied by 010, 011, 111.
So therefore $\exists \exists \exists, \exists \exists \forall, \forall \exists \exists$
are satisfied.

\end