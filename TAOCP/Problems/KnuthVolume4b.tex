\def\newstep#1{\smallskip \noindent {\bf #1}}
\def\newprob#1{\vskip 0.12in \noindent {\bf #1}}

\topglue 0.5in
\centerline{\tt Mathematical Preliminaries Redux}
\vskip 0.3in

\noindent {\bf Problem 1} {\it Non-transitive dice}\hfil\break
(a) ${\rm Pr}\left(A > B\right) = 2 / 3$ (chance of $A$ rolling a 5) $\times 5 / 6$
(chance that a 5 beats $B$) = 5 / 9.  And ${\rm Pr}\left(B > C\right) = 2 / 6 \times 2 / 6$
($B = 3$) $ + 3 / 6 \times 4 / 6$ ($B = 4$) $+ 1 / 6 \times 4 / 6$ ($B = 6$)
$ = 1 / 9 + 1 / 3 + 1 / 9 = 5 / 9$, ${\rm Pr}\left(C > A\right) = 2 / 6 \times 2 / 6 +
2 / 6 \times 2 / 6 + 2 / 6 = 1 / 9 + 1 / 9 + 1 / 3 = 5 / 9$.\hfil\break
(b) The die should not have any common faces between them or we could make a better
die by making use of any unused ones.  So we want to partition {1, 2, 3, 4, 5, 6} somehow between
three die, also specifying how many times each one appears.  Because we are only trying find
{\it a} solution, not prove it is optimal, we don't need to be that rigorous.

Start by considering the case where one die is all of one value.  It obviously can't be 6, or
that die would alway win.  Say it has value $a \times 6$.  Now, say, that die B also all one
face $b \times 6$.  We must have $a > b$ (and then $P\left(A > B\right) = 1$.   Clearly
die C can't also be all one value, since then we couldn't have B beating C anc C beating A.
So, say that c has two values, with $c_2 > c_1$.  Then we must have $c_2 > a$ and $c_1 < a$.
We must also have $b > c_1$ so that B can beat C.  But then we can't have both 
$P\left(C > A\right) > 1/2$ and $P \left(B > C\right) > 1/2$ because we run out of faces.
Adding a third value to C does not help.

So, if A is pure, B can't be.  So now we consider only one pure die -- say B also has two values
$b_2 > b_1$.  We must have $a > b_2$ so that $P\left(A > B\right) > 0$.  If we also had 
$a > b_1$ then A would also beat B.  We must have $c_1 > a$ so that C can beat B,
but we can't have $c_2 > a$ or else B would lose to C.  So we must have $c_1 > a > c_2$ and $a > b_2$.
If we then have $a > b_1$ then $P\left(C > B\right) \leq N_{c_2}$, $P \left(A > C\right) = N_{c_1}$,
so this doesn't work.  We conclude that having A be pure doesn't seem t owork.

So, try two values per die, with $a_1 > a_2, b_1 > b_2, c_1 > c_2$.  Try A is $a_1, 5 \times a_2$
and C is $k_c c_1, \left(6-k_c\right) \times c_2$, and we have
$$
 P\left(C > A\right) = {k_c \over 36} \left[c_1 > a_1\right] + {5 k_c \over 36} \left[c_1 > a_2\right]
  + {\left(6 - k_c\right) 5 \over 36} \left[c_1 > a_2\right],
$$
so we must have $c_1 > a_2$ to obtain the desired possibilities, and $P\left(C > A\right) = k_c / 6$,
and we need $k_c \geq 5$.  So: A is $1 \times a_1, 5 \times a_2$ and C is $5 \times c_1, 1 \times c_2$.

Now B is $k_b \times b_1, \left(6 - k_b\right) \times b_2$.  We must have $a_1 > b_1$, so 
$$
P\left(A > B\right) = {1 \over 6} + {5 k_b \over 36} \left[a_2 > b_2\right] + {5 \left(6-k_b\right) \over 36}
 \left[a_2 > b_2\right] \geq {1 \over 6} + {5 \left(6 - k_b\right) \over 36} \left[a_2 > b_2\right].
$$
This means that we must have $k_b \leq 3$.

And
$$
 P\left(B > C\right) = {k_b \over 6} \left[b_1 > c_1\right] + {6 - k_b \over 36} \left[b_2 > c_2\right]
  + {\left(6 - k_b\right) 5 \over 36} \left[b_2 > c_1\right].
$$
Since $k_b \leq 3$, we must have $b_2 > c_2$ and $b_1 > c_1$.  This still gives us a lower limit of 
$k_b \geq 3$, so together we have $k_b = 3$.

Putting this all together: A is $1 \times a_1, 5 \times a_2$, B is $3 \times b_1, 3 \times b_2$,
C is $5 \times c_1, 1 \times c_2$ with $a_1 > c_1 > a_2 > c_2$ and $b_1 > c_1$ and $b_2 > c_2$.
This can be done with $A = 6 3 3 3 3 3$, $B=5 5 5 2 2 2$, $C = 4 4 4 4 4 1$.\hfil\break
(c) Clearly we want to try splitting each die into $F_m = F_{m-1} + F_{m-2}$.  Try making
one of the die all one value -- say A is $F_m \times a$, B is $F_{m-2} \times b_1, F_{m-1} \times b_2$.
If $b_1 > a > b_2$, then $P\left(A > B\right) = F_{m-1} / F_m$.  If then C is $F_{m-1} \times c_1,
F_{m-2} \times c_2$ with $c_1 > a > c_2$ then $P\left(C > A\right) = F_{m-1} / F_m$, and
$P\left(B > C\right)$ is complex.

So, this seems to work, but B should be the singleton.  That is: $A = F_{m-1} \times a_1, F_{m-2} \times a_2$,
$B = F_m \times b$, $C = F_{m-1} \times c_1, F_{m-2} \times c_2$, and we can get two of the
probabilities if $c_2 > b > c_1$ and $a_1 > b > a_2$, with 
$P\left(C > A\right) = \left(F_{m-1} F_{m-2} + F_{m-2} F_m\right) / F^2_m$ 
if $c_1 > a_2$ and $c_2 > a_1$.  That is: $c_2 > a_1 > b > c_1 > a_2$, which we can get by 
using $A = F_{m-1} \times 4, F_{m-2} \times 1$, $B = F_m \times 3$, 
$C = F_{m-1} \times 2, F_{m-2} \times 5$.

But does this work? $P\left(C > A\right)$ is complex enough to suggest that it might work,
but needs to be simplified.  Start with the Cassini identity: 
$$
 \eqalign{
    F_{n+1} F_{n-1} - F_n^2 =& \left(-1\right)^n \cr
   \left(F_{n+2} - F_{n}\right)  F_{n-1} - F_n^2 =& \left(-1\right)^n \cr
   \left(F_{n+2} - F_{n}\right)  \left(F_n - F_{n-2}\right) - F_n^2 =& \left(-1\right)^n \cr
   F_{n+2} F_n - F_n^2 - F_{n+2} F_{n-2} + F_n F_{n-2} - F_n^2 =& \left(-1\right)^n \cr
   F_{n+2} \left(F_n - F_{n-2}\right) - 2 F_n^2 + F_n F_{n-2} =& \left(-1\right)^n \cr
   F_{n+2} F_{n-1} - F_n \left(2 F_n - F_{n-2}\right) =& \left(-1\right)^n \cr
   F_{n+2} F_{n-1} - F_n \left(F_n + F_{n-1}\right) =&  \left(-1\right)^n \cr
   F_{n+2} F_{n-1} - F_n F_{n+1} =&  \left(-1\right)^n \cr
   F_{n-1} F_{n+2} =& F_n F_{n+1} + \left(-1\right)^n \cr
   F_{m-2} F_{m+1} =& F_{m-1} F_m - \left(-1\right)^{m-1}
 }
 $$
 which, when substituted into $P\left(C > A\right)$ gives the desired result.

\newprob{Problem 6} {\it Pairwise independence does not imply $k$-wise independence}\hfil\break
Note that the individual components can't be fully independent, or there would be no way to have a vector
with two set values have non-zero probability but 1 or 3 have zero probability.
Also note that there are $n \choose 2$ ways to have $x_1 + \ldots + x_n = 2$,
so the chance that 2 are set is 
$$
{n \choose 2} \times {1 \over \left(n - 1\right)^2} =
{n \left(n - 1\right) \over 2} \times {1 \over \left(n - 1\right)^2} = {n \over 2 \left(n - 1\right)}.
$$
Combined with the chance that zero are set $\left(n - 2\right) / \left(2 n - 2\right)$,
the total probability is one.

In any case, we want to compute the probability that $X_i = 1$.  Given $X_i = 1$, there are $n - 1$
ways to set $X_j = 1$ for $i \neq j$, all of equal probability, and all other settings have zero probability.
Therefore, the probability that $X_i = 1$ must be $1 / \left(n - 1\right)$ so that the sum of
all those arrangements adds up to the right value.  What about $\left(X_i, X_j\right) = \left(0, 1\right)$ 
for $i \neq j$? Well, there are $n-2$ other choices for $X_k = 1$, so the probability
must be $\left(n - 2 \right) / \left(n - 1\right)^2$, and we must have the same probability
for $\left(X_i, X_j\right) = \left(1, 0\right)$.  We already know that the chances of
$\left(X_i, X_j\right) = \left(1, 1\right) = 1 / \left(n - 1\right)^2$ for $i \neq j$,
so by subtraction we must have the chances of them both being 0 of
$\left(n - 2\right)^2 / \left(n - 1\right)^2$.

Now note that these can be written as the probability that ${\rm Pr} \left(X_i, X_j\right) = 
\left(0, 0\right), \left(0, 1\right), \left(1, 0\right), \left(1, 1\right) =
p_0^2, p_0 p_1, p_1 p_0, p_1^2$ for $p_0 = {\left( n - 2\right) / \left(n - 1\right)}$,
$p_1 = 1 / \left(n - 1\right)$, which constitutes 2-wise independence.
But we can't have $\left(X_i, X_j, X_k\right) = \left(0, 0, 0\right)$ for any distinct
$i, j, k$, and the same is true for any combination of 4 or more.  So they are 2-wise
independent, but no more.

\newprob {Problem 10} {\it k-wise independence modulo $p$}\hfil\break
Note a similar (but simpler) version is discussed as example~15.1.1 of Mitzenmacher and Upfal.
The basic idea is to show that $P\left(X_1 = a_1, \dots, X_k = a_k\right) = 1 / p^k$, and if it turns
out that there is a unique map from the $Y$s to the $X$s, this will be true because the $Y$s are
independent.

First, note that if $n > p$ then $X_{p+1} = \left( \left(p+1\right)^m + Y_1 \left(p+1\right)^{m-1}
 + \ldots + Y_m\right) \bmod p =X_1$, so they are definitely not unique.  Why?  Well, because
 $\left(p + 1\right)^k \bmod p = \left[ \sum_q {m \choose q} p^k  \right] = {m \choose 0} \bmod p = 
 1 \bmod p$.  So therefore there is no independnece unless $n \leq p$.  Now, the 1 terms (that don't
 involve the $Y$s) are just constants we can ignore.

 As long as the vectors $1, j, \ldots, j^{m-1}$ are independent, then the solution is unique, otherwise
 there would be multiple ways to formulate the solution.  Note, however, that the vectors don't have
 to span the space, so for a given set of values of the $Y$s not all $X$s are possible!  And, indeed,
 these vectors are unique modulo $p$ as long as there are less than $m$ of them, so this formulation
 gives $m-1$-wise independence.

\newprob {Problem 13} {\it Does $P\left(A|B\right) > P\left(A\right)$,
$P\left(B | C\right) > P\left(B\right)$ imply $P\left(A|C\right) > P\left(A\right)$?}\hfil\break
Writing it out in terms of the definition does not suggest any way of demonstrating
this, but is there a counterexample?  Yes, a particularly simple one is 
$\Omega = {1, 2, 3, 4, 5}$, $P\left(i\right) = 1/5$ for $i \in \Omega$, and
$A = {1, 2, 3}$, $B = {2, 3, 4}$, $C = {3, 4, 5}$.  For then
$ P\left(A\right) = P\left(B\right) = P\left(C\right) = 3 / 5$
and
$$
 \eqalign{
  P\left(A | B\right) = {P\left({2, 3}\right) \over P\left(B\right)} = {2 \over 3} >& P\left(B\right) \cr
  P\left(B | C\right) = {P\left({3, 4}\right) \over P\left(C\right)} = {2 \over 3} >& P\left(C\right) \cr
 P\left(A | C\right) = {P\left({3}\right) \over P\left(C\right)} = {1 \over 3} <& P\left(C\right) \cr
 }.
$$

\newprob {Problem 14} {\it Prove the chain rule for conditional probability.}\hfil\break
That is:
$$
  P\left(A_1 \cap \ldots \cap A_n\right) = P\left(A_1\right) P\left(A_2 | A_1\right)
   \ldots P\left(A_n | A_1 \ldots A_{n-1} \right).
$$

Proceed via induction.  First, the base case 
$P\left(A_1 \cap A_2\right) = P\left(A_2 | A_1\right) P\left(A_1\right)$
is true by the definition of conditional probability (MPR.4).  So now assume we have
the above relation and want to demonstrate it for $n+1$.  If we denote $A_1 \cap A_n = An$,
then this is simply $P\left(An\right) = P\left(A_1\right) \ldots P\left(A_n | A_1 \ldots A_{n-1}\right)$,
and we have (from the definition) that 
$P\left(A_{n+1} \cap An\right) = P\left(A_{n+1} | An\right) P\left(An\right)$
which is just the desired formula.

\newprob {Problem 15} {\it Is $P\left(A | B \cap C\right) P\left(B | C\right) = P\left(A \cap B | C\right)$?}\hfil\break
Writing this out:
$$
P\left(A | B \cap C\right) P\left(B | C\right)  = {P\left(A \cap B \cap C\right) \over P\left(B \cap C\right)}
   {P\left(B \cap C\right) \over P\left(C\right)} = {P\left(A \cap B \cap C\right) \over P\left(C\right)} =
    P\left(A \cap B | C\right).
$$
So this is true as long as we avoid the special case $P\left(C\right) = 0$ 
(and then it's true if $A$ and $B$ are independent).

\newprob {Problem 17} {\it Evaluate $P\left(\hbox{\rm T is ace} | \hbox{\rm B is Q of spades}\right)$}. 
\hfil \break
Four of the remaining 51 cards are aces, so this is just $4/51$.

\newprob {Problem 18} {\it Prove that $\hbox{\rm Var}\left[x\right] 
\leq \left(M - E\,X\right) \left(E\,X - m\right)$}.\hfil\break
Here $M$ is the maximum value and $m$ the minimum.  Denoting the quantity
as $Q$, we are trying to prove $\hbox{\rm Var}\left[x\right] \leq Q$, which is 
equivalent to  $Q - \hbox{\rm Var}\left[x\right] \geq 0$.
$$
\eqalign{
  \hbox{\rm Var}\left[x\right] =& E\left(X^2\right) - \left(E\,X\right)^2 \cr
  Q =& \left(M + m\right) E\,X - \left(E\,X\right)^2 - m\,M \cr
  Q - \hbox{\rm Var}\left[x\right] =& \left(M+m\right) E\,X - E\left(X^2\right) -m\,M .
}
$$
Is the latter quantity positive?  Well, $\left(M - X\right) \left(X - m\right) \geq 0$, so
it's expectation must also be positive.
$$
\eqalign{
  E\left(M - X\right)\left(X - m\right) & \geq \cr
  E\left(\left(M + m\right) X - X^2 -m\,M\right) & \geq 0 \cr
  \left(M + m\right) E\, X - E\left(X^2\right) \geq 0 
}
$$
which is the desired proof.

\newprob {Problem 20} {\it Prove the Union bound: $P\left(A_1 
\cup \ldots \cup A_n\right) \leq P\left(A_1\right) + \ldots P\left(A_n\right).$}\hfil\break
There are multiple ways to show this, but doing it with equation~8:
$$
\eqalign{
  P\left(A_1 \cup \ldots \cup A_n \right) &= 
           E\left( \left[A_1 \cup \ldots \cup A_n \right] \right) \cr 
    &= E\, \hbox{\rm max}\left( \left[A_1\right], \ldots, \left[A_n \right] \right) \cr
    &\leq E\left(\left[A_1\right] + \ldots + \left[A_n \right]\right) \cr
    &= E\left[A_1\right] + \ldots + E\left[A_n\right] \cr
    &= P\left(A_1\right) + \ldots + P\left(A_n\right)
}
$$
where the last step follows by linearity of expectations.  The more
standard way is just induction -- it is true for any two events because
$$
P\left(A_1 \cup A_2\right) = P\left(A_1\right) + P\left(A_2\right) - P\left(A_1 \cap A_2\right)
$$
and, since probabilities are non-negative, the last term in particular must be $\ge 0$ and therefore
$P\left(A_1 \cup A_2\right) \le P\left(A_1\right) + P\left(A_2\right)$.  Since the union of any two 
events is itself an event, this extends to arbitrarily many events trivially.

\newprob {Problem 34} {\it Write out an algebraic proof of (12)}\hfil\break
That is, show $E\left(X\right) = E\left( E\left(X | Y \right) \right)$.  
First, notice that
$E\left(X|Y\right)$ is just a function of $Y$ -- that is, a random variable which
takes the value $\sum_x \, x Pr\left(X=x| Y = y\right)$ when $Y=y$.  Or to write
it out more fully
$$
E\left(X|Y\right)\left(\omega\right) =
    \sum_{\omega^{\prime} \in \Omega} X\left(\omega^{\prime}\right)
      \left[Y\left(\omega\right) = Y\left(\omega^{\prime}\right)\right]
      {Pr\left(\omega^{\prime}\right) \over Pr \left(Y = Y\left(\omega\right)\right)}.
$$
Thus we have
$$
 \eqalign{ 
  \sum_{\omega} E \left(X | Y\right) Pr \left(\omega\right) &=
     \sum_{\omega} Pr\left(\omega\right) \sum_{\omega^{\prime}}
      X\left(\omega^{\prime}\right) Pr\left(\omega^{\prime}\right)
       \left[Y\left(\omega^{\prime}\right) = Y\left(\omega\right)\right] /
       Pr\left(Y = Y\left(\omega\right)\right) \cr
     &= \sum_{\omega} Pr\left(\omega\right) \sum_{\omega^{\prime}}
       X\left(\omega^{\prime}\right) Pr\left(\omega^{\prime}\right)
        \left[Y\left(\omega^{\prime}\right) = Y\left(\omega\right)\right] /
        Pr\left(Y = Y\left(\omega^\prime\right)\right) \cr
    &= \sum_{\omega^\prime} X\left(\omega^{\prime}\right) Pr\left(\omega^{\prime}\right) 
      \sum_{\omega} Pr\left(\omega\right)
         \left[Y\left(\omega^{\prime}\right) = Y\left(\omega\right)\right] /
         Pr\left(Y = Y\left(\omega^\prime\right)\right) \cr
 }
$$
where the second sum is just one because it is the definition:
$Pr\left(Y = Y\left(\omega\right)\right) \equiv \sum_{\omega^{\prime}} Pr\left(\omega^{\prime}\right)
\left[Y\left(\omega\right) = Y\left(\omega^{\prime}\right)\right].$

\newprob {Problem 35} {\it True or false for conditional expectations.}\hfil\break
(a) $E\left( E\left(X | Y\right) | Y \right) = E\left(X | Y\right)$.  following on
from the previous problem,
$$
\eqalign{
   E\left( E\left(X | Y\right) | Y \right) \left(\omega\right)  &=
     \sum_{\omega^{\prime}} \sum_{\omega^{\prime \prime}}
       X\left(\omega^{\prime\prime}\right)
       \left[Y\left(\omega^{\prime\prime}\right) = Y\left(\omega^{\prime}\right)\right]
       {Pr\left(\omega^{\prime\prime}\right) \over Pr\left(Y = Y\left(\omega^{\prime}\right)\right)}
       \left[Y\left(\omega^{\prime}\right) = Y\left(\omega\right)\right]
       {Pr\left(\omega^{\prime}\right) \over Pr\left(Y = Y\left(\omega\right)\right)} \cr
   &=  \sum_{\omega^{\prime \prime}}
     \left(
     X\left(\omega^{\prime\prime}\right)
     \left[Y\left(\omega^{\prime\prime}\right) = Y\left(\omega\right) \right]
     {Pr\left(\omega^{\prime\prime}\right) \over Pr\left(Y=Y\left(\omega\right)\right)}
     \sum_{\omega^{\prime}} 
      { \left[Y\left(\omega\right) = Y\left(\omega^{\prime}\right)\right]
         Pr\left(\omega^{\prime}\right) 
         \over Pr \left(Y = Y\left(\omega^{\prime}\right)\right) }.
     \right)
}
$$
where we have swapped the equalities in the indicator functions because they must all be equal for a term to count.
The last sum is 1 by the definition of $Pr\left(Y = Y\left(\omega\right)\right)$ (see the Notes for this portion),
which leaves us with $E\left(X | Y\right) \left(\omega\right)$, as claimed.\hfil\break
(b) $E\left(E\left(X|Y\right)|Z\right) = E\left(X|Z\right)$.  This one is not true.  We now have
$E\left(E\left(X|Y\right)|Z\right) = \sum_y f\left(Y, Z\right) Pr\left(Z=z\right)$, but that isn't
going to be $\sum_x x Pr\left(Z=z\right)$ in general.  In contrast, consider
$$
\eqalign{
  E\left(E\left(X|Y, Z\right)|Z\right) &= 
    \sum_{y^{\prime}, x} Pr\left(X=x|Y=y^{\prime}, Z=z\right) Pr\left(Y=y^{\prime}| Z = z\right) \cr
    &= \sum_x Pr\left(X=x|Z=z\right) \cr 
    &= E\left(X|Z\right)
}.
$$

\newprob{Problem 36} {\it Simplify conditional expectations}\hfil\break
(a) Simplify $E\left(f\left(X\right) | X\right).$  This is simply $f\left(X\right)$\hfil\break
(b) Simplify $E \left( f\left(Y\right) E\left(g\left(X\right) | Y\right) \right)$.  Recall that
the conditional expectation is just a random variable.
$$
\eqalign{
E \left( f\left(Y\right) E\left(g\left(X\right) | Y\right) \right)
 &= \sum_y f\left(y\right) E\left(g\left(X\right) | Y\right) Pr\left(Y=y\right)\cr
 &= \sum_{x, y}f\left(y\right) g\left(x\right) Pr\left(X=x | Y=y\right) Pr\left(Y=y\right) \cr
 &= \sum_{x, y} f\left(y\right) g\left(x\right) 
   {Pr\left(X=x , Y=y\right) \over Pr\left(Y=y\right)} Pr\left(Y=y\right) \cr
  &= \sum_{x, y} f\left(y\right) g\left(x\right) Pr\left(X=x, Y=y\right) \cr
  &= E\left( f\left(Y\right) g\left(X\right)\right)
}
$$

\newprob{Problem 37} {\it Suppose $X_1, \ldots, X_n$ is a random permutation of 
$\{1, \ldots, n\}$}.  What is $E\left(X_k | X_1, \ldots, X_{k-1}\right)?$.\hfil\break
$X_k$ is equally likely to be any of the values in 
$\{1, \ldots, n\} \ \{X_1, \ldots, X_{k-1}\}$.  So it's average value must be
$$
 {
  \sum_{i=1}^n i - \sum_{i=1}^{k-1} X_i \over n + 1 - k
 } = {
  n \left(n + 1\right) / 2 - \sum_{i=1}^{k-1} X_i \over n + 1 - k
 }.
$$

\newprob{Problem 46} {\it Explain why ${\rm E}\left(X^2 | X > 0\right) \geq 
\left({\rm E} \left(X | X > 0\right)\right)^2$}\hfil\break
There are (at least) two ways to look at this, and neither of them depends on the $X > 0$
part.  So I'll drop that.  First, there's the usual ${\rm E}\left( \left(X - {\rm E} \, X\right)^2 \right) =
{\rm E} \, X^2 - \left({\rm E}\, X\right)^2$ where the square is manifestly non-negative.
Second, $X^2$ is convex so we can simply use Jensen's inequality.

\newprob{Problem 47} {\it If $X$ is random and $Y = {\rm max}\left(0, X\right)$,
show that $E Y \ge E X$ and $E Y^2 \le E X^2$} \hfil\break
This simply follows from the fact that $Y \ge X$ and $Y^2 \le X^2$.

\newprob{Problem 49} {\it If $X$ is random and $X \ge 0$ then prove that
 ${\rm Pr}\left(X = 0\right) \le E X^2 / \left(E X\right)^2$}\hfil\break
 First, we have that ${\rm Pr}\left(X = 0\right) = 1 - {\rm Pr} \left(X > 0\right)$,
 since $X$ is positive.  From the second moment inequality (22) we have
 ${\rm Pr}\left(X > 0\right) \ge \left(E X\right)^2 / E X^2$ so this must satisfy
 ${\rm Pr}\left(X = 0\right) \le 1 - \left(E X\right)^2 / E X^2 =
 \left(E X^2 - \left( E X \right)^2\right) / E X^2$.  But we also know that
 $E X^2 \ge \left(E X\right)^2$ (Problem~46), so in turn we have
 $$
 {\rm Pr}\left(X > 0\right) 
  \le \left(E X^2 - \left(E X\right)^2\right) / \left(E X\right)^2
  = E X^2 / \left(E X\right)^2 - 1
$$ 
as claimed.

\newprob{Problem 75} {\it Find an interesting margingale for Bernard Friedman's urn}
\hfil\break
Friedman's urn (introduced in Problem~74) is just like Polya's urn except that you
add a ball of the opposite color instead of the same color.  Similar to the analysis there,
the number of red balls at level $n$ is $R_n = X_1 + \ldots + X_n$.  What is the relation
between $R_{n+1}$ and $R_n$?  Well, $E\left(R_{n+1} | R_n, \ldots, R_1\right) =
E\left(R_{n+1} | R_n\right)$ because all the information that we need to know
is contained in $R_n$ and the fact that there are $n+2$ balls.  Each visit to the
urn changes the value of $r$ to $r + 1$ with probability $b / \left(n + 2\right)$
by drawing a black ball or leaves it unchanged ($r$) with probability
$r / \left(n + 2\right)$.  Putting these together means that
$$
 E\left(R_{n+1} | R_n \right) = R_n {R_n \over n + 2} + \left(R_n + 1\right)
   {B_n \over n + 2} = 1 + R_n \left(1 - {1 \over n + 2}\right) =
   1 + R_n {n + 1 \over n + 2}.
$$
If we want to form a martingale from $R_n$, we need to figure out what to 
add/subtract/multiply to make the terms go away, keeping in mind that the
$n$ will change.  If we define $Z_n = \alpha_n R_n + \beta_n$
then the requirement
$$
 E\left(Z_{n + 1} | Z_1, \ldots, Z_{n-1} \right) = E\left(Z_{n+1} | Z_n\right)
$$
becomes
$$
 \alpha_{n+1} + \alpha_{n+1} R_n + \beta_{n+1} = \alpha_n R_n + \beta_n .
$$
This does not have a unique solution, but we can cancel the $R_n$ terms
if we use $\alpha_n = n + 1$ leaving $\beta_{n+1} + n + 2 = \beta_n$.
This, again, doesn't have a unique solution, but if we want to make 
$\beta_n = -1$ to cancel off that $+1$ in the $R_n$ occurrance
then we get $\beta_n = \left(n + 2\right) \left(n + 1 \right) / 2$.
Altogether then:
$$
 Z_n = \left(n + 1\right) R_n - {\left(n + 2\right) \left(n + 1\right) \over 2},
$$
but any other solution to the above relations also works.

\newprob{Problem~91} {\it Prove that Doob's general formula (39) always defines a
martingale}\hfil\break
The definition of a Doob martingale is 
$$
 Z_n = E \left( Q | X_0, \ldots, X_n\right).
$$  
Now we must find the martingale expectation:
$$
\eqalign{
 E\left(Z_{n+1} | X_0, \ldots, X_n \right) 
   &= E\left( E\left(Q | X_0, \ldots, X_n, X_{n+1}\right) | X_0, \ldots, X_n\right) \cr
   &= E\left( Q | X_0, \ldots, X_n \right) \cr
   &= Z_n .\cr
}
$$
where the second step took advantage of the conditional expectation formula; recall
that the formula still works in conditional spaces, so 
$E\left( E\left(X | Y_1, \ldots, Y_n, Z\right) |
Y_1, \ldots, Y_n \right) = E\left(X | Y_1, \ldots, Y_n \right)$ (as discussed
in the companion notes).

\topglue 0.5in
\centerline{\tt Knuth 7.2: Basic Backtracking}
\vskip 0.3in

\noindent {\bf Problem~1} {\it Generating Combinatoric Quantities using 
Backtracking}\hfil\break
(a) $n$-tuples: $D_k$ is whatever the domain is and $P_l$ is always 
true.\hfil\break 
(b) Permutations: $D_k = \{ 1, \ldots, n \}$ and $P_l$ is that all the elements 
are distinct.\hfil\break
(c) Combinations: $D_k = \{1, \ldots, N + 1 - k \}$ and 
$P_l = x_1 < \ldots < x_l$.\hfil\break

\newprob {Problem~2} {\it Making $P_1$ always true}\hfil\break
Simply discard any elements of $D_1$ that do not satisfy $P_1$.
So it is possible to make $P_1$ unless there are no such elements.

\newprob {Problem~3} {\it Saving half the work for $n$-queens}\hfil\break
Restrict $D_1$ to be only the first half of the range, and then add the 
reflected solution $n + 1 - x_1, \ldots, n + 1 - x_n$.  For example, if $n = 8$
then $D_1 = \{1, 2, 3, 4\}$.

\newprob {Problem~4} {\it Recursive backtracking}\hfil\break
{\bf I1.} [Initialize] Set $l \leftarrow 0$ and initialize other data 
structures.\hfil\break
{\bf I2.} [Test $P_l$] If $P_l\left(x_1 \ldots x_l\right)$ set 
 $l \leftarrow l + 1$ and $x_l \leftarrow {\rm min}\,D_l$,
  otherwise goto {\bf I4}.\hfil\break 
{\bf I3.} [Visit] If $l > n$ visit $x_1 \ldots x_n$, set $l \leftarrow l-1$.
\hfil\break
{\bf I4.} [Iterate] Set $x_l$ to the next larger element in $D_l$ and goto 
 {\bf I2}. If there is no such element set $l \leftarrow l - 1$.\hfil\break
{\bf I5.} [Done] If $l=0$ halt, otherwise goto {\bf I2}.
\hfil\break

So, why not use something like this?  Really, the answer is because Don Knuth
is an assembly programmer, and that's the way he thinks.  One could argue his
algorithm is faster, which could be critical in large problems, but tests show
the difference is small when coded in a higher level language -- in fact this
way is sometimes faster.

\newprob {Problem~5} {\it NQueens skipping one row.}\hfil\break
For $n=8$, skipping row $0, 1, \ldots, 7$ gives ${312, 396,
430, 458, 458, 430, 396, 312}$ solutions.

\newprob {Problem~9} {\it Bitwise N-Queens}\hfil\break
Obviously we will represent the current state of the $A_l, B_l, C_l$ 
as integers $a_l, b_l, c_l$, one for each level, and where, for example, 
$a_l\left[i\right] = 1$ if and only if $x_{i-1}$ is present in $A_l$.  
Similarly, $S_l$ will be represented by integers $s_l$.  Let 
$m = \left(1 \ll {n-1}\right)$, which is a bitmask on the available elements
for $x$.

Then in {\bf W2}, to compute the available values,
$s_l \leftarrow m \,\&\, {\bar a_{l-1}} \,\&\, {\bar b_{l-1}} \,\&\, 
{\bar c_{l-1}}$. We compute the bitwise representation of the current choice 
for $x$ to chose as $x \leftarrow s_l \& \left(- s_l\right)$, then 
$a_l \leftarrow a_{l-1} + t$, $b_l \leftarrow \left(b_{l-1} + t\right) \gg 1$, 
and  $c_l \leftarrow \left( {c_{l-1} + t} \ll 1 \right) \,\&\, m$.  The shifts 
are necessary for $b, c$ because $l$ has increased.  In {\bf W4} we
remove that choice by doing $s_l \leftarrow s_l - t$, although since we keep
all the $s_l$, we can do it in W2 if desired.

\newprob {Problem 15} {\it Hexwise N-Queens}\hfil\break
This is like N-Queens except we only need to check one diagonal.  This turns out
to be like ignoring $b$ from Problem~9.

Then we have $n=1: 1, 2: 1, 3: 3, 4: 7, 5: 23, 6: 83, 7: 405, 8: 2113, 9: 12657,
10: 82297$.

\newprob {Problem 20} {\it Forced move in Langford.}\hfil\break
We need a new array $a$ where $a_i$ means that $i$ has already appeared.
We initially set it to all 0s, and when we chose the value in {\bf L3}
we set $a_k \leftarrow 1$.  Similarly, when we undo in $L_5$ we set
$a_k \leftarrow 0$.

The more interesting changes have to do with forcing a value.  First,
we don't need to do any checks if $l < n - 1$ since nothing can be forced
before that.  We force moves in {\bf L3}, after we determine we are not
off the end (that is, after the $l + k + 1 \le 2 n$ check), we check to see 
if the forced value has already been used.  If it has, continue, if not
then we have to force it by walking the list forward until it is selected.
So: if $l \ge n - 1$ and $a_{2n - l - 1} = 0$, while $l + k + 1 \ne 2 n$
set $j \leftarrow k$, $k \leftarrow p_k$.  We are guaranteed this will
terminate because we know it is available by checking $a$.

But we can also modify $l$ by walking over used values in {\bf L2}, which
may lead us to realize we are out of room.  So, in {\bf L2} while looping
forward over negative values, we immediately backtrack (jump to {\bf L5}).
So: while $x_l < 0$, if $l \ge n - 1$ and $a_{2 n - l - 1} = 0$ goto {\bf L5},
otherwise set $l \leftarrow l + 1$.


\topglue 0.5in
\centerline{\tt Knuth 7.2.1: Dancing Links}
\vskip 0.3in

\noindent {\bf Problem 3} {\it Solving exact cover problems using
linear algebra}\hfil\break
(a) Together $x_2 + x_4 = 1$ and $x_2 + x_4 + x_6 = 1$
imply that $x_6 = 0$.  Combined that with $x_1 + x_6 = 1$
gives $x_1 = 1$.  In turn with $x_1 + x_3 = 1$ this implies
$x_3 = 0$, then with $x_3 + x_5 = 1$ we have $x_5 = 1$.
Then $x_3 + x_4 = 1 \rightarrow x_4 = 1$ and finally
$x_2 + x_4 = 1 \rightarrow x_2 = 0$.  Altogether
$\vec{x} = [1, 0, 0, 1, 1, 0]$.\hfil\break
(b) Because in general there will be many, many more
rows than columns ($m \gg n$), and so the solution
will not be uniquely determined.

\newprob {Problem~4} {\it Exact cover on graph.}\hfil\break
You are chosing edges such that each vertex has exactly one incident edge.
This has various interpretations depending on the graph.  If it is bipartite, for
example, each solution choses the vertices of one part.

\newprob {Problem~6} {\it Size of data structures in Algorithm~D}\hfil\break
The items occupy $N+1$ locaions of size 2 + the space to represent the names.
Then we have $N$ header nodes plus $M+1$ spacers plus the $L$ options,
each taking 3 elements, so $3\left(L + N + M + 1\right)$ locations.

\newprob {Problem~7} {\it Explain specific values in Table~1}\hfil\break
(a) {\tt TOP(23) = -4} because it is a spacer following option 4 (this is not
really part of the algorithm; all that matters is that it is negative.\hfil\break
(b) {\tt DLINK(23) = 25} because that is the last element of the next option
(option 5).

\newprob {Problem~8} {\it Design an algorithm to set up the initial memory
contents for Algorithm~X}\hfil\break
My implementation differs slightly from the way the book approaches it.  First,
I required the items to be sortable so that the entry order for the options
doesn't affect the solution (it may find solutions in a different order, 
however, depending on the option order).  The items from each input option
are read into two BTrees (one primary, one secondary).  They are checked for
overlaps -- if any are found it's an error -- and then read out into a flat
array where the first $N_p$ items are primary followed by $N_s$ secondary items.
Each option is converted into an indexed form where the primary and secondary
items are replaced by indices into the items array.  The next step is to
build the item nodes (the ones with rlink/llink), which are simply built
by iterating over the item list in order, but adding the 0 node at one end
and the secondary item header node at the end, and modifying the last primary
item to RLINK to node 0 and the first secondary to LLINK to the secondary
header.  In my implementation the item nodes don't hold the actual items,
those are kept in a separate list.  This allows the header nodes to be smaller
so they are more likely to be in cache -- the items are only needed when a
solution is found, and the process of looking up the items involves indirection
anyways, so there's no loss.

Then the option nodes are built.  First, create a new spacer, then create 
header nodes for each primary and secondary item.  Add another spacer, and then,
for each option, iterate over the primary items and secondary items,
inserting each into the doubly linked list for the respective header node
and updating len for that item, finishing with another spacer that points back 
to the first node added for the option.

\newprob {Problem~9} {\it MRV Heuristic}\hfil\break
Simply walk the list of active items and keep track of the minimum encountered
so far.\hfil\break
{\bf M1.} [Initialize] If $RLINK\left(0\right) = 0$, terminate unsuccessfully (there are no
 active items).  Otherwise, set $m \leftarrow \infty$, $p \leftarrow 0$ ($m$ will hold
 the current minimum).\hfil\break
{\bf M2.} [Walk forward] Set $p \leftarrow RLINK\left(p\right)$.\hfil\break
{\bf M3.} [Done?] If $p = 0$ goto {\bf M6}.\hfil\break
{\bf M4.} [Compare] Set $l \leftarrow LEN\left(p\right)$.  If $l < m$ set $m \leftarrow l$,
 $i \leftarrow p$.\hfil\break
{\bf M5.} [Early terminate] If $m \ne 0$, goto {\bf M2}.\hfil\break
{\bf M6.} [Exit] Return $i$.

\newprob {Problem~13} {\it How can we use the values of $x_0\ldots x_{l-1}$ to 
figure out what the solution is?}\hfil\break
Each $x_i$ is the item that was used to select a given option.  So, we
essentially apply the solution of Problem~12 to each value: set $r \leftarrow x_i$,
output the item associated with ${\rm TOP}\left(r\right)$, 
and then repeat until $r = x_i$: set $r \leftarrow r + 1$, then if 
${\rm TOP}\left(r\right) < 0$ set $r\leftarrow {\rm ULINK}\left(r\right)$,
otherwise output the item for ${\rm TOP}\left(r\right)$.  If you prefer the
items to be in order, you can walk backwards until you find the preceding
spacer, and then walk forward until finding the following spacer.

\newprob {Problem~15} {\it What options can you omit to eliminate mirror 
solutions for the Langford problem?}\hfil\break
A very simple approach is to force $1$ to be in the left half by simply
omitting all items $1\,s_j\,s_{j+2}$ where $j \ge n$.  Knuth suggests it's
more efficient to work with $i = n$.

\newprob {Problem~18} {\it What are the solutions to (6) if $e$, $f$, $g$ 
are secondary?}\hfil\break
The previous solution still works of course (`ce', `adf', `bg').  But in
addition `adg', `bcf' is now a solution (which doesn't cover `e').

\newprob {Problem~33} {\it Given an exact cover problem, construct another
problem with exactly one more solution}\hfil\break
Add one new item which is in none of the existing options, and two new
options.  The first contains only the new item, the second contains all items.
Every solution to the previous solution is still a solution with the first
option added, and there is one more consisting purely of the second option.

\newprob {Problem~202} {\it Form the $\oplus$ sum of two search trees.}\hfil\break
This is obviously hard to do in text, but we can talk through what to do at
each level.
\vskip 0.05in
\noindent The root node is aA.\hfil\break
\noindent The branching factors of a and A are the same, but a is on the
left, so we branch there first, forming bA and cA.
\noindent For bA, the branching factors of b and A are again the same, so form
dA and eA.\hfil\break
\noindent For cA, the branching factor of c is more, so we branch on A, forming
cB and cC.\hfil\break
\noindent dA is a solution, so we get d paried with everything below A. In 
particular, dF is a solution.\hfil\break
\noindent eA is a backtrack node, so it is also a failure node, and so a leaf.
\hfil\break
\noindent cB, B doesn't branch, so form cD.\hfil\break
\noindent cC, C has a lower branching factor than c, so form cE and cF.\hfil\break
\noindent cD - D is a backtrack node, so it is a leaf.\hfil\break
\noindent cE, E doesn't branch so form cG.\hfil\break
\noindent cF, F is a solution node, so we get a copy of everything below c
with F.  In particular, hF is a solution.\hfil\break
\noindent cG - G is a backtrack node, so terminate.\hfil\break

\newprob {Problem~203} {Is the $\oplus$ operation on search trees associative?
Commutative?}\hfil\break
It is associative, since the matrix sum is -- recall that $A \oplus A^{\prime}$
is just putting $A$ in the upper left and $A^{\prime}$ in the lower right and
filling the corners with 0, and that is associative.  It is not commutative
though because of the 1) favor the left when each side has the same number
of branches and 2) early termination rule when hitting a backtrack node.
Consider the simple search tree $A$ with three nodes and no branching ending
in a backtrack and $B$ the same thing but with two nodes.  In that case
$A \oplus B = A$, but $B \oplus A = B$.

\newprob {Proboem~266} {\it Sketch the design of a utility program that will
create polynomino options to fill a shape.}\hfil\break
First we generate all reflections and rotations of each polynomino, removing
duplicates.  It's also possible to have the caller specify the symmetries
(Knuth's version does this), but it is probably safer to just remove duplicates.
This can be done by a) normalizing all the coordinates (so that the min x and
min y are both zero) and b) sorting the resulting cells by $x$ with $y$ as a
tiebreaker.  This puts each polynomino rotation/reflection into a canonical
form with a defined sort order so duplicates can be easily removed.

Then try placing each polynomino at every position in the shape, and, if all
the cells are contained, add an appropriate option.  For some shapes you can
do a bit better by keeping track of the $x, y$ extents of each polynomino, but
that's a bit harder -- or at least less useful -- with irregular shapes.

\newprob {Problem~268} {\it There are 1010 ways to pack the 12 pentominoes into 
a $5 \times 12$ box.  What's a good way to do so?}\hfil\break
Well, use Problem~266 to set up the options.  But perhaps more usefully, we
want to remove the symmetry.  One possibility is to require that the $X$ piece
be in the upper left quadrant -- $X$ is appropriate because it is fully symmetric
so we don't have to worry about the interaction between the shape and having
it in one quadrant.  This doesn't entirely work though when the center square
of $X$ is in the middle row because you can then reflect top to bottom.  To
remove this symmetry by adding a secondary item to the centered options,
and add the same one to all options where some other piece is flipped over.

\newprob {Problem~271} {\it How can you find the 2339 ways to pack the 
pentominoes into a $6 \times 10$ box?}\hfil\break
This is very like Problem~268, but you don't need to add the special item
because there is no central row/column.


\topglue 0.5in
\centerline{\tt Knuth 7.2.2.2: Satisfiability}
\vskip 0.3in

\newprob{Problem 1} The shortest unsatisfiable set of clauses is the
empty clause $\epsilon$, the shortest satisfiable set is the empty set $\emptyset$.

\newprob{Problem 20} Define clauses $waerden\left(k_0, \ldots, k_{b-1}; n \right)$
that are satisfiable if and only if $n < W\left(k_0, \ldots, k_{b-1}\right)$.\hfil\break
We have to introduce one variable for each possible value of an $x$: let
$x_{i;a}$ mean that $x_i = a$ where $1 \le i \le n$ and $0 \le a < b$.  Then
we require that at least one value is set for each $x_i$: $x_{i0} \vee
x_{i;1} \vee \ldots \vee x_{i;b-1}$ for all values of $i$.  We also
need to impose the spacing requirements, which are $\overline{x}_{i;a} \vee
\overline{x}_{i + s;a} \vee \ldots \vee \overline{x}_{i+ \left(k_a - 1\right)s;a}$
for all $d \ge 1$ and $1 \le i \le n - \left(k_a - 1\right)d$.  Note that this
formulation allows both $x_{i;a}$ and $x_{i;b}$ for $a \ne b$ -- you can introduce
pairwise clauses to force only one is set, or you can leave them out because
they represent multiple solutions and so are harmless.

\newprob{Problem~26} Prove that Sinz's clauses (18) and (19) enforce the cardinality
constraint $x_1 + \ldots + x_n \le r$.\hfil\break

\noindent The four cases for the clauses can be spelled out:\hfil\break
1. $\overline{s}_j^k \vee s_{j+1}^k$ for $j \in [1, n-r)$, 
$k \in \left[1 - r\right].$\hfil\break
\hskip 1em
2. $\overline{x}_{j+k} \vee \overline{s}_j^k \vee s_j^{k + 1}$ for
$j \in \left[ 1, n - r \right]$, $k \in [1, r).$\hfil\break
\hskip 1em
3. $\overline{x}_j \vee s_j^1.$\hfil\break
\hskip 1em
4. $\overline{x}_{j+r} \vee \overline{s}_j^r.$\hfil\break
\hskip 1em

\noindent The hint is to show that these conditions imply 
$s_j^k = 1$ whenever $x_1 + \ldots + x_{j + k - 1} \ge k$.

The first set of clauses is: $s_j^k \vee s_{j+1}^k$ for $1 \le j < n - r$ and
$1 \le k \le r$.  These are pretty simply just $s_1^k \le s_2^k \le \ldots \le s_{n-r}$.
That is, once you have set $s_j^k = 1$, you also have $s_{>j}^k = 1$.
The second set of clauses are $\overline{x}_{j+k} \vee \overline{s}_j^k \vee s_j^{k+1}$
for $1 \le j \le n - r$ and $0 \le k \le r$.  Translated in a similar fashion
this is $x_{j+k}\,s_j^k \le s_j^{k+1}$.  The final two clauses are just boundary
conditions .

The hint follows by induction.  First, the base case: $k = 1$, $j = 1$.
The third item is then just $\overline{x}_1 \vee s_1^1$, or $x_1 \Rightarrow s_1^1$
(and hence $s_j^1$ for all $j$ by the first set of clauses), which is the base case.

Next assume that $s_{j}^k$, $x_1 + \ldots + x_{j + k - 1} \ge k$, and extend
by induction.  There are two cases: increasing $j$ or increasing $k$.  Either
on brings $x_{j+k}$ into the hint.  First consider increasing $j$.  We already
had $x_1 + \ldots x_{j+k-1} \ge k$, and this remains true whe nwe add $x_{j+k}$
no matter it's value.  So what we want to prove is that $s_{j+1}^k$ -- but we
alredy have that from the first property ($s_j^k \Rightarrow s_{j+1}^k$).

Next consider increasing $k$ (but not $j$).  Now we do care about the value
of $x_{j+k}$ -- specifically, we want to show that if 
$x_1 + \ldots + x_{j + k - 1} = k$, then $x_{j+k} \Rightarrow s_j^{k+1}$.
But we already had $s_j^k$ from the inductive hint, so the item 2 is simply
$\overline{x}_{j+k} \vee s_j^{k+1}$ -- exactly what we wanted.  So the hint
is proved true by induction.  Now -- how does this solve the problem?

There are two things to prove: that if $x_1 + \ldots x_n > r$, the clauses
cannot be satisfied, and that they can be satisfied for $x_1 + \ldots x_n \le r$.
The latter is just what we have been doing above -- you just set $s_j^k$ 
according to the hint ($s_j^k = 1$ if and only if $x_1 + \ldots + x_{j+k-1} \ge k$).

For the former, consider $j = n - r$ and $k = r$.  Then we have that
$x_1 + \ldots + x_{n-1} = r \Rightarrow s_{n-r}^r$.  Now we add $x_n$.
We want the clauses to be unsatisfiable if $x_n$, but still satisfiable if
$x_n$.  Item 4 is $\overline{x}_n \vee \overline{s}_{n-r}^r$.
So this is satisfiable if $\overline{x}_n$, but 
$x_n \Rightarrow \overline{s}_{n-r}^r$. But this contradicts the implication 
from the hint when we hadn't include $x_n$, so the clauses are not satisfied.  
Furthermore, if $x_1 + \ldots + x_{n-1} < r$, there is no problem -- we can 
satisfy all the clauses using the hint logic as before.

\newprob{Problem~87}: Explain why the clauses (42) represent Alice and Bob's
programs (40).\hfil\break
Denoting Alice's states at time $t$ by $A0_t, \ldots, A4_t$ and Bob's by $B0_t, \ldots, B4_t$,
the first set of clauses expresses the fact that neither can change state unless it is their turn.
If we couple this with clauses that require that both Alice and Bob can only be in one
state, these can be written $@_k \vee \overline{AK_{k}} \vee AK_{k+1}$
and $\overline{@_k} \vee \overline{BK_{k}} \vee BK_{k+1}$.  For example, if Alice is in state
A0 at time $t$, then this states that if $@_k = 0$ then she must still be in A0 at
time $t+1$.

The next set of clauses represent possible transitions.  For example, if it is
Alice's turn ($@_t = 1$) and she is in state $A2$, she has to go to $A3$, which becomes
$\overline{@_k} \vee {\overline A2_k} \vee A3_{k+1}$.  For $A0$ there are two possible
target states, although we could ignore non-transitions as irrelevant to the problem:
$\overline{@_k} \vee {\overline A0_k} \vee A0_{k+1} \vee A1_{k+1}$.  For A1 it's a bit more
complicated because it depends on $l$, so we get two rules: first, for $l=1$
$\overline{@_k} \vee \overline{A1_{k}} \overline{l_k} \vee A1_{k+1}$; then, for $l=0$
$\overline{@_k} \vee \overline{A1_{k}} \vee l_k \vee A2_{k+1}$.  To express the $A2$ and $A4$
changes to $l$: $\overline{@_k} \vee \overline{A2_k} \vee l_{k+1}$ and
$\overline{@_k} \vee \overline{A4_k} \vee \overline{l_{k+1}}$.  And finally, we encode
that $l$ doesn't change except in states $A2$ and $A4$ with
$\overline{@_k} \vee l_k \vee A2 \vee A4 \vee \overline{l_{k+1}}$
and $\overline{@_k} \vee \overline{k_t} \vee A2 \vee A4 \vee l_{k+1}$.
There are similar clauses for $BK$ but with $@_k$ instead of $\overline{@_k}$.

\newprob {Problem 121}: Lower level operations in Algorithm~A
\newstep {A3} [Remove $\bar l$].  Because of the reverse order the variables are
stored in, and the fact that the algorithm chooses values for $x_1, x_2, \ldots, x_n$
in order, we can remove $\bar l$ from all clauses that contain it simply by
reducing the value of {\tt SIZE} for those clauses by one.  We can find the clauses
by following the circular links until we get back to the head of the list.
The messy bit is that when a clause would go to size 0 we need to undo
what we have already done because the set of clauses has become unsatisfiable
given the current assignments.  Thus: $p \gets {\tt F}\left(l \oplus 1\right)$ 
(follow the forward links to clauses that contain $\bar l$).  Repeat until
we come back to the head of the list (so, as long as $p \ge 2 n + 2$):
i) Get the clause number: $c \gets {\tt C}\left(p\right)$. ii) If ${\tt SIZE}\left(c\right) > 1$,
 decrease it by 1 and $p \gets {\tt F}\left(p\right)$.  If not, we need to undo what
 we've already done.  So interrupt the previous
 loop, set $p = {\tt B}\left(p\right)$ and repeat as long as $p \ge 2 n + 2$:
 i) Get the clause $c \gets {\tt C}\left(p\right)$. ii) ${\tt SIZE}\left(c\right) += 1$.
 iii) $p \gets {\tt B}\left(p\right)$ and go to A5.
\newstep {A4} [Remove all clauses that contain $l$].  Here we simply iterate
over all other literals in each clause that contains $l$ and unlink them from
the circular lists.  So: set $p \gets {\tt F}\left(l\right)$ and repeat as
long as $p \ge 2 n + 2$: i) set $c \gets {\tt C}\left(p\right)$ ($c$ is
the clause number), ii) for ${\tt START}\left(c\right) \le k < {\tt START}\left(c\right)
 + {\tt SIZE}\left(c\right) - 1$ (loop over all other literals in this clause)
 remove the literal $k$ using the procedure following below, iii) set $p \gets {\tt F}\left(p\right)$.
 To remove the literal pointed to by $k$ a) set $d \gets {\tt F}\left(k\right)$,
 $e \gets {\tt B}\left(k\right)$, ${\tt B}\left(d\right) \gets e$, ${\tt F}\left(e\right) \gets d$
 (the variable is removed from the circular list), b) decrement the counter for that
 literal: ${\tt C}\left({\tt L}\left(k\right)\right) -= 1$. The final overall step is
 to set $a \gets a - {\tt C}\left(l\right)$ (correct the number of active clauses),
 and $d \gets d + 1$ (we've set another variable).
\newstep {A7} [Reactivate $l$s clauses] This takes advantage of the 
 Dancing Links procedure.  Because we haven't changed {\tt F} or {\tt B} for the variables
 we removed in A4, we can put them back in efficiently.  So, $p \gets {\tt B}\left(l\right)$
 and while $p \ge 2 n + 2$ do: $c \gets {\tt C}\left(p\right)$, and for
 ${\tt START}\left(c\right) \le k < {\tt START}\left(c\right) + {\tt SIZE}\left(c\right) - 1$
add the literal $k$ by doing $d \gets {\tt F}\left(k\right)$, $e \gets {\tt B}\left(k\right)$,
${\tt B}\left(d\right) \gets k$, ${\tt F}\left(e\right) \gets k$, and 
${\tt C}\left({\tt L}\left(k\right)\right) += 1$, and $p \gets {\tt B}\left(p\right)$.
Then, finally, $a \gets a + {\tt C}\left(l\right)$.
\newstep {A8} [Unremove $\bar l$] $p \gets {\tt F}\left(l \oplus 1\right)$,
and repeat until $p \ge 2 n + 2$: $c \gets {\tt C}\left(p\right)$,
${\tt SIZE}\left(c\right) += 1$, $p \gets {\tt F}\left(p\right)$.  Then go to A5.

\vskip 0.08in \noindent {\bf Problem 109} Find the lexicographically smallest
solution.\hfil\break
First, find a solution.  If you can't, terminate unsuccessfully.  Then take your
solution and find the first 1.  Say it's at position $j$.  Next, try to find a solution
with $x_1 x_2 \ldots x_j = 0$ by adding additional clauses that force those
to your problem.  If you do find a solution, repeat.  If not, say that then next
1 after $j$ is in position $k$.  Now try for a solution with $x_1 \ldots x_{j-1} = 0$
and $x_k = 0$, repeating until there are no more $k$s to try.

Finding the largest is similar, but somewhat more complicated.

\newprob {Problem 124} Fill in the steps in B2.\hfil\break
We want to walk the linked list of clauses that watch $\bar l$.  So, set
$c \gets W_{\bar l}$.  If $c = 0$, there are no clauses watches $\bar l$, so
terminate successfully.  Otherwise, while $c \ne 0$ do: $i_{min} \gets {\tt START}
\left(c\right)$, $i_{max} \gets {\tt START}\left(c - 1\right)$, $c^{\prime} \gets 
{\tt LINK}\left(c\right)$ (this will be the update for the next clause).
Now, for $i_{min} < k < i_{max}$, set $l^{\prime} \gets {\tt L}\left(k\right)$.
Now, if the literal represented by $l^{\prime}$ isn't false, we've found
something else to watch, so we swap it to the front of the clause (meaning we
watch it): ${\tt L}\left(i_{min}\right) \gets l^{\prime}$, ${\tt L}\left(k\right) \gets \bar l$,
${\tt LINK}\left(c\right) \gets W_{l^{\prime}}$, $W_{l^{\prime}} \gets c$, $c \gets c^{\prime}$
and exit the $k$ loop (we now move on to the next clause watching $\bar l$.
If we reach the end of the $k$ loop without finding such a literal, then the formula
is unsatisfiable with the current settings, so we go to step B5.

Now, how do we check if a literal is already false?  Well, Algorithm~B steps
through the literals in order, so the condition for the literal to not be false is
$| l^{\prime} | > d$ (not set) or $| l^{\prime} | + m_{| l^{\prime} |}$ is even (is set,
but set to be true.

\newprob {Problem 125} Modify Algorithm~B to find all solutions.
\newstep {B2}  [Visit or choose] If $d > n$, visit the solution represnted by $m_1 \ldots m_n$
(recall $x_j \gets 1 \oplus \left( m_j \& 1 \right)$ constructs $x$) and go to B6.
\newstep {B6} [Backtrack or terminate] Terminate if $d=1$.  Otherwise set $d \gets d - 1$.

\newprob {Problem 126} Find the next step of Algorithm~D on (59)\hfil\break
The book has a mistake -- the active ring is $\left(6\,9\,7\,8\right)$, since 
$\bar 5$ was just set.  So, first it looks at 6, but there are no unit clauses forced
(the possibilities would be $\bar 1 \bar 2 \bar 6$, $\bar 1 \bar 5 \bar 6$, $\bar 2 \bar 5 \bar 6$,
$346$, none of which are present). So next it tries 9, which {\it does} exist in a unit 
clause (1 5 9), so this is chosen.  That affects the watch list of $\bar 9 \bar 3 \bar 6$ --
$39$ are set, so we switch to watching 6 by converting it to $\bar 6 \bar 3 \bar 9$.
The active ring loses 9, so becomes $\left(6\,7\,8\right)$.

\newprob {Problem 127} Move codes for (59) right before and after backtrack.\hfil\break
$m = 1 1 4 1 4 5 4 5$; note that we don't need $h$, we can just follow the steps
in order.  But $h = 1 2 3 4 6 9 7 8$.  After the backtrack, $m = 1 1 4 2$ (we try
a different setting for 4 after the first one failed.

\newprob {Problem 128} Show what Algorithm~D does on the Rivest clauses (6).
\hfil\break
Following the layout used in problem~123, we have
$$
\matrix{
p =       & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 & 13 & 14 
   & 15 & 16 & 17 & 18 & 19 & 20 & 21 & 22 & 23 \cr
{\tt L} = & 5 & 2 & 9 & 3 & 9 & 7 & 8 & 7 & 5 & 6 & 5 & 3 & 4 & 3 & 8
 &2 & 8 & 6 & 9 & 6 & 4 & 7 & 4 & 2 \cr
}
$$
with ${\tt START}\left(j\right) = 24 - 3 j$,
$W_l = \{3, 7, 4, 8, 5, 1, 6, 2\}$ for $2 \le l < 10$, and
${\tt LINK}\left(j\right) = 0$ for $1 \le j \le 8$.
\newstep {D1} sets ${\tt NEXT} = \{2, 3, 4, 1\}$ with $h = 1$, $t = 4$.
 The active ring is $\left(1 2 3 4\right)$.
\newstep {D2} sets $k \gets 4$.
\newstep {D3} There are no unit clauses yet.
\newstep {D4} $h \gets {\tt NEXT}\left(t\right) = {\tt NEXT}\left(4\right) = 1$,
 $m_1 \gets 1$, so we are trying $\bar 1$.
\newstep {D5} $d \gets 1$, $h_1 \gets 1$, $k \gets 1$.  $t \ne k$, so delete $1$
from the ring by setting ${\tt NEXT}\left(4\right) \gets {\tt NEXT}\left(1\right) = 2$
and $h \gets 2$.  We now have ${\tt NEXT} = \{2 3 4 2\}$, and the active
ring is $\left(2 3 4 \right)$.
\newstep {D6} We update the watches by doing $b \gets \left(m_1 + 1\right)\, {\rm mod}
\, 2 = 0$, $x_1 \gets 0$, and clearing the watch list for $1$, which is watched by $C_3 = 
341$.  The net effect of the steps carried out in exercise~130 is to change
this clause to $3 1 4$ by changing the relevant part of the link table ($15 \le p \le 18$)
from $2 8 6$ to $8 2 6$, setting $W = \{0, 7, 4, 8, 5, 1, 3, 2 \}$ and ${\tt LINK}\left(3\right)
= 6$.
\newstep {D2} $k \gets 4$.
\newstep {D3} $h \gets {\tt NEXT}\left(k\right) = 2$.  There are no unit clauses.
\newstep {D4} $h \gets {\tt NEXT}\left(t\right) = 2$, $m_2 \gets 1$ (trying $\bar 2$).
\newstep {D5} $d \gets 2$, $h_2 \gets 2$, $k \gets 2$.  We have $x = \{ 0 0 - - \}$
and $h = \{1 2 - - \}$.  We delete $2$ from the ring by setting 
$h \gets 3$ and ${\tt NEXT} = 2 3 4 3$ -- the active ring is now $\left(3 4\right)$.
\newstep {D6} Clear the watch list for 2, which is $C_4 = 4 \bar 1 2$.
This is accomplished by changing $C_4$ to $4 2 \bar 1$ by
changing the values of the link table $12 \le p \le 14$ to $348$,
changing $W = \{0, 4, 0, 8, 5, 1, 3, 2 \}$ and setting ${\tt LINK}\left(4\right) = 7$.
\newstep {D2} $k \gets 4$.
\newstep {D3} Now we do have a unit clause: $C_1$ has become $\bar 3$
since we have $\bar 1 \bar 2$.  $h \gets 3$, so $f \gets 2$, so
$m_3 \gets 5$ (forced $\bar 3$), $t \gets 4$.
\newstep {D5} $d \gets 3$, $h_3 \gets 3$, $k \gets 3$ and
 $h \gets 4$, ${\tt NEXT} = 2 3 4 4$ (the active ring is 4).
\newstep {D6} $x_3 \gets b \gets 0$, and clear the watch list for 3, which is
$C_5 = \bar 1 \bar 2 3$, and which is changed to $\bar 1 3 \bar 2$.
At this point, we have
$$
\matrix{
p =       & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 & 13 & 14 
   & 15 & 16 & 17 & 18 & 19 & 20 & 21 & 22 & 23 \cr
{\tt L} = & 5 & 2 & 9 & 3 & 9 & 7 & 8 & 7 & 5 & 5 & 6 & 3 & 3 & 4 & 8
 &8 & 2 & 6 & 9 & 6 & 4 & 7 & 4 & 2 \cr
}
$$
with $W = \{0, 4, 0, 5, 0, 1, 3, 2 \}$ and ${\tt LINK} = \{0, 0, 6, 7, 8, 0, 0, 0\}$,
$m = \{1 1 5 -\}$, $h = \{1 2 3 -\}$, and ${\tt NEXT} = 2 3 4 4$.
\newstep {D2} $k \gets 4$.
\newstep {D3} Now we have two unit clauses, $4, \bar 4$ from $ 341 , 234$ respectively.
So we have to backtrack!
\newstep {D7} $t \gets 4$.  $m_3 = 5 \ge 2$, so $k \gets h_3 = 3$, $x_3$ is unset,
$W_7 \ne 0$ so $h \gets 3$, ${\tt NEXT} = 2 3 4 3$ () and $d \gets 2$.  The
active ring is now $\left(3 4\right)$. ($m_2 < 2$).
\newstep {D8} $m_2 \gets 3 - 1 = 2$ (trying $x_2 = 1$ after $x_2 = 0$ failed).

This is enough to see how the algorithm works.  In particular, note that the
clause re-ordering done by exercise~130 is different than the solution Knuth
gives for this problem -- which is fine, if perhaps slightly confusing.

Anyways, to spell it out:
$$
\matrix{
{\rm Ring}     & x_1 & x_2 & x_3 & x_4 & {\rm Units} & {\rm Choice} & {\rm Changed} & 
 {\rm Notes} \cr
\left(1\,2\,3\,4\right) & - & - & - & - & & \bar 1 & 341 \rightarrow 314 & w_3=7, m_1 = 1\cr
\left(2\,3\,4\right) & 0 & - & - & - & & \bar 2 & 4 \bar 1 2 \rightarrow 4 2 \bar 1 &
 w_5 = 8, m_2 = 1\cr
\left(3\, 4\right) & 0 & 0 & - & - & \bar 3 & \bar 3 & \bar 1 \bar 2 3 \rightarrow \bar 1 3 \bar 2 &
h = 1\,2\,3\,- , m = 1\,\,1\,5\,- \cr
\left(4\right) & 0 &  0 & 0 & - & 4, \bar 4 & {\rm Backtrack} & & 
{\rm State} = \{1 2 \bar3, 2 3 \bar 4, 3 1 4, 4 2 \bar1, \bar1 3 \bar 2, \bar 2 \bar 3 4,
 \bar 3 \bar 4 \bar 1, \bar 4 1 \bar 2 \}\cr
\left( 3\, 4 \right) & 0 & - & - & - & & 2 & \bar 1 3 \bar 2 \rightarrow \bar 1 \bar 2 3
& m = 1\,2\,-\,- \cr
& & & & & & & \bar 4 1 \bar 2 \rightarrow \bar 2 1 \bar 4 & \cr
\left(3\,4\right) & 0 & 1 & - & - & \bar 4 & \bar 4 & \bar2 \bar 3 4 \rightarrow \bar 2 4 \bar 3 &
 h = 1\,2\,4\,-, m = 1\,2\,5\,- \cr
\left(3\right) & 0 & 1 & - & 0 & \bar 3, 3 & {\rm Backtrack} & & 
{\rm State} = \{ 1 2 \bar 3, 2 3 \bar 4, 4 1 3, 4 2 \bar 1, \bar 1 \bar 2 3, \bar 2 4 \bar 3,
\bar 3 \bar 4 \bar 1, \bar 2 1 \bar 4 \} \cr
\left(4 3 \right) & - & - & - & - & & 1 & \bar 3 \bar 4 \bar 1 \rightarrow \bar 3 \bar 1 \bar 4 &
 m = 2\,-\,-\,- \cr
 & & & & & & & 4 2 \bar 1 \rightarrow 4 \bar 1 2 & \cr
\left( 2 \, 4 \, 3\right) & 1 & - & - & - & & 2 & {\rm None} & m = 2\, 0\, - \, - \cr
\left(4\, 3\right) & 1 & 1 & - & - & 3 & 3 & 1 2 \bar 3 \rightarrow 1 \bar 3 2 &
 m = 2\,0\,4\,-\cr
 & & & & & & & \bar 2 4 \bar 3 \rightarrow \bar 2 \bar 3 4 & \cr
\left(4 \right) & 1 & 1 & 1 & - & 4, \bar 4 & {\rm Backtrack} & &
 {\rm State} = \{ 1 \bar 3 2, 2 3 \bar 4, 4 1 3, 4 \bar 1 2, \bar 1 \bar 2 3, \bar 2 \bar 3 4,
 \bar 3 \bar 1 \bar 4, \bar 2 1 \bar 4 \} \cr
\left(3\, 4\right) & 1 & - & - & - & & \bar 2 & 1 \bar 3 2 \rightarrow 1 2 \bar 3 & \cr
 & & & & & & & 4 \bar 1 2 \rightarrow 2 \bar 1 4 & \cr
\left(3 \, 4 \right) & 1 & 0 & - & - & 4 & 4 & \bar 2 1 \bar 4 \rightarrow \bar 2 \bar 4 1 & \cr
 & & & & & & & 2 3 \bar 4 \rightarrow 2 \bar 4 3 & \cr
 & & & & & & & \bar 3 \bar 1 \bar 4 \rightarrow \bar 4 \bar 1 \bar 3 & \cr
\left(3\right) & 1 & 0 & - & 1 & 3, \bar 3 & {\rm Failure} & \cr
}
$$

\newprob {Problem~129} Subroutine to return 1 if a literal $l$ is a unit.
\newstep {K1} [Initialize] Set $c \gets W_l$.
\newstep {K2} [Terminate?] If $c = 0$, return 0 (no unit clauses found).
\newstep {K3} [Start a new clause] $s \gets {\tt START}\left(c\right) + 1$.
\newstep {K4} [Return success if all other literals false] 
  If $s = {\tt START}\left(c - 1\right)$, return 1 (a unit clause was found).
\newstep {K5} [Move to next literal? ]
  If this literal is false ($x_{\left| L \left(s\right) \right|} = {\tt L} \left(s\right) \& \, 1$,
recalling that $\left| {\tt L}\left(s\right) \right| = {\tt L}\left(s\right) \gg 1$)
 set $s \gets s + 1$ and return to {\bf K4}.
\newstep {K6} [Try next clause] Set $c \gets {\tt LINK}\left(c\right)$ and go to {\bf K2}.

\newprob {Problem~224} Resolution trees.\hfil\break
The point of this exercise is to prove the statement in the text (p 55) that `we can prove
the empty clause by resolution from $F | \bar{x}$ if and only if we can prove $x$ by
resolution from $F$ without resolving on $x$' by converting a resolution tree that
refutes $F | \bar{x}$ into a resolution tree on $F$.  Well -- that's easy enough.
Start with the axioms (members of $F | {\bar x}$), and for every such clause that is
not also a clause of $F$, add $x$ back in to the label.  Then also add $x$ to every
child of that clause (that is: every vertex reachable from such a clause).  If any
labels changed, then we will end up converting the empty clause $\epsilon$ into $x$,
which proves what we set out to prove.

\newprob {Problem~249} Carry out Algorithm~IA on $\{1234, 1 \bar 2, \bar 1 \bar 2 \bar 3,
\bar 1 3, 2 \bar 3, 3 \bar 4 \}$\hfil\break
Starting from the beginning:
\newstep {I1} $d \gets 0$, $m \gets 6$
\newstep {I2} $d \gets 1$, $l_1 \gets 3$, leaving $\{-, 1 \bar 2, \bar 1 \bar 2, -, 2, - \}$
\newstep {I2} $d \gets 2$, since the shortest is $C_5 = 2$.  So $l = \left(3\,2\right)$,
 and we have $\{-, 1, \bar 1, -, -, - \}$.
\newstep {I2} $d \gets 3$, $l_3 \gets 1$, $l = \left(3\,2\,1\right)$.
\newstep {I3} Now $C_3 = \bar 1 \bar 2 \bar 3$ is falsified (so $i \gets 3$).
\newstep {I4} Set $l_3 \gets \bar 1$, and now $C_2 = 1 \bar 2$ is falsified.  So $j = 2$.
\newstep {I5} $m \gets 7$, learn $C_7 = C_2 \diamond C_3 = 1 \bar 2 \diamond \bar 1 \bar 2 \bar 3 = 
 \bar 2 \bar 3$.  Now $d \gets 2$ ($l_2 = \bar 2$, and 2 is in the new clause $\bar 2 \bar 3$.
 Also, $i \gets 7$.
\newstep {I4} Now we try to learn things from our new clause. $l_2 \gets \bar 2$ (so
$l \left(3\, \bar 2\right)$), and now $C_5 = 2 \bar 3$ is falsified (so $j \gets 5$).
\newstep {I5} Learn $C_8 = C_5 \diamond C_7 = 2 \bar 3 \diamond \bar 2 \bar 3 = \bar 3$.
  Now $d \gets 1$ ($\bar {l_1}$ is the only literal in the new clause), $l_1 \gets \bar 3$, $i \gets 8$.
\newstep {I4} No clauses are falsified.
\newstep {I2} $d \gets 2$, and the unsatisfied clauses are $\{124, 1 \bar 2, -, \bar 1, -, \bar 4, -, -\}$.
  We can chose either $\bar 2$ or $\bar 4$.  Choosing the former (which now diverges from Knuth's
  solution), $l_2 \gets \bar 2$.
\newstep {I3} No clauses are falsified.
\newstep {I2} $d \gets 3$, $l_3 \gets \bar 2$, leaving clauses $4, \bar 4$.
\newstep {I3} None falsified.
\newstep {I2} $d \gets 4$, $l_4 \gets 4$, so we have $l = \left(\bar 3\, \bar 1\, \bar 2\, 4\right)$.
\newstep {I3} $C_6 = 3 \bar 4$ is falsified, so $i \gets 6$
\newstep {I4} Trying $l_4 \gets \bar 4$, and $C_1 = 1234$ is falsified ($j \gets 1$).
\newstep {I5} Learn $C_9 = 1234 \diamond 3 \bar 4 = 123$.  Now $d \gets 3$, $i \gets 9$.
\newstep {I4} $l_3 \gets 2$, so $l = \left(\bar 3\, \bar 1\, 2\right)$.  This falsifies $C_2 = 1 \bar 2$,
 $j \gets 2$.
\newstep {I5} Learn $C_{10} = 123 \diamond 1 \bar 2 = 13$, $i \gets 10$, $d \gets 2$.
\newstep {I4} $l_2 \gets 1$, $l = \left(\bar 3\,1\right)$, and $C_4 = \bar 1 3$ is falsified.
\newstep {I5} Learn $C_{11} = C_{10} \diamond C_4 = 1 \bar 2 \diamond \bar 1 3 = 3$,
 and $d \gets 1$, $i \gets 11$.
\newstep {I4} $l_1 \gets 3$, $C_8 = \bar 3$ is falsified.
\newstep {I5} And finally we learn $C_12 = C_11 \diamond C_8 = \bar 3 \diamond 3 = \epsilon$,
 so we have shown the original clauses are unsatisfiable.  The final set of clauses is
 $\{1234, 1 \bar 2, \bar 1 \bar 2 \bar 3,
\bar 1 3, 2 \bar 3, 3 \bar 4, \bar 2 \bar 3, \bar 3, 1 2 3, 1 3, 3, \epsilon \}$.

\newprob {Problem 253} Extend the Algorithm~C example on $waerden\left(3;3;9\right)$ \hfil\break
Starting with the specified decision 5, this becomes
$$
\matrix{
 t & L_t & {\rm Level} & {\rm Reason} \cr
 0 & \bar{6} & 1 & \Lambda \cr
 1 & 4 & 1 & 46 \cr
 2 & 5 & 2 & \Lambda \cr
 3 & \bar{3} & 2 & \bar{3} \bar{4} \bar{5} \cr
 4 & 9 & 2 & 369 \cr
 5 & \bar{1} & 2 & \bar{1}\bar{5}\bar{9}\cr
 6 & \bar{7} & 2 & \bar{5}\bar{7}\bar{9}\cr
 7 & 2 & 2 & 123 \cr
 8 & 8 & 2 & 678 \cr
 9 & \bar{2} & 2 & \bar{2} \bar{5} \bar{8} \cr
}
$$
and the last one conflicts with $t=7$.  So we have the conflict clause $\bar{2} \bar{5} \bar{8}$.  
The rightmost complemented literal of this clause in the trail is $L_7 = 2$, which has reason 123, so we
resolve it to form $\bar{2} \bar{5} \bar{8} \diamond 1 2 3 \rightarrow 1 3 \bar{5} \bar{8}$.
This has all it's complemented literals on level 2, so it's still a conflict clause.  The rightmost
in the trail is now 8 with reason 678, so the next step is 
$1 3 \bar{5} \bar{8} \diamond 6 7 8 \rightarrow 1 3 \bar{5} 6 7$.  There are still multiple level
2 complemented literals, the rightmost is $\bar 7$ with reason $\bar{5} \bar{7} \bar{9}$, so
$1 3 \bar{5} 6 7 \diamond 5 \bar{7} \bar{9} \rightarrow 1 3 \bar{5} 6 \bar{9}$.
This has $\bar{1} \bar{3} 5 9$ on level 2, the rightmost of which is $\bar{1}$ with reason 
$\bar{1} \bar{5} \bar{9}$, so $1 3 \bar{5} 6 \bar{9} \diamond \bar{1} \bar{5} \bar{9}
\rightarrow 3 \bar{5} 6 \bar{9}$, next on 9 with reason 369 to get
$3 \bar{5} 6 \bar{9} \diamond 3 6 9 \rightarrow \bar{3} 5 6$.  Both 3 and $\bar{5}$ are on level 2,
so we resolve with the reason for $\bar{3}$, $\bar{3} \bar{4} \bar{5}$ to get
$3 \bar{5} 6 \diamond \bar{3} \bar{4} \bar{5} \rightarrow \bar{4} \bar{5} 6$.
This, finally, has only one complemented literal on level 2 (5), so it's done.  We can now discard
level 2 entirely, and append this new clause.  Note that the order was different than
in Knuth's solution, but the result was the same.

Exercise~257 points out that $\bar{4} \bar{5} 6$ can be further simplified to $\bar{5} 6$ here,
but I will ignore that in my solution because it's a later exercise.  So:
$$
\matrix{
 t & L_t & {\rm Level} & {\rm Reason} \cr
 0 & \bar{6} & 1 & \Lambda \cr
 1 & 4 & 1 & 46 \cr
 2 & \bar{5} & 1 & \bar{4} \bar{5} 6 \cr
 3 & 7 & 1 & 5 6 7 \cr
 4 & \bar{1} 1 & \bar{1} \bar{4} \bar{7} \cr
 5 & 3 & 1 & 1 3 5 \cr
 6 & 9 & 1 & 1 5 9 \cr
 7 & \bar{2} & 1 & \bar{2} \bar{3} \bar{4} \cr
 8 & \bar{8} & 1 & \bar{7} \bar{8} \bar{9} \cr
 9 & 8 & 1 & 2 5 8 \cr
}
$$
and we have another conflict clause, this time with reason 258.  Now the rightmost
is $\bar{8}$, so $2 5 8 \diamond \bar{7} \bar{8} \bar{9} \rightarrow 2 5 \bar{7} \bar{9}$.
Next $\bar{2}$ with reason $\bar{2}\bar{3}\bar{4}$: $2 5 \bar{7} \bar{9} \diamond 
\bar{2} \bar{3} \bar{4} \rightarrow \bar{3} \bar{4} \bar{7} \bar{9}$.  The rightmost
is now 9 with reason 159, so $\bar{3} \bar{4} \bar{7} \bar{9} \diamond 1 5 9
\rightarrow 1 \bar{3} \bar{4} 5 \bar{7}$, next $3 / 1 3 5$ to form
$1 \bar{3} \bar{4} 5 \bar{7} \diamond 1 3 5 \rightarrow 1 \bar{4} 5 7$.
Then $\bar{1} / \bar{1} \bar{4} \bar{7}$ to get 
$1 \bar{4} 5 7 \diamond \bar{1} \bar{4} \bar{7} \rightarrow \bar{4} 5$.
Almost there! The reason for $\bar{5}$ is our new-ish clause $\bar{4} \bar{5} 6$,
and when we resolve $\bar{4} 5 \diamond \bar{4} \bar{5} 6 \rightarrow \bar{4} 6$,
and then finally the reason for 4 to get $\bar{4} 6 \diamond 46 \rightarrow 6$.

This now becomes a new unit clause and we start at level 0 -- clearly no longer
choosing $\bar{6}$ to start!

\bye